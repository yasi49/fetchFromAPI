{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yasi49/fetchFromAPI/blob/main/chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XtkvGSL9sumA"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U langgraph langsmith langchain_anthropic langchain_google_genai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1Th7bPYttLjS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"quickstart\"\n",
        "\n",
        "gemini_api_key = userdata.get('GEMINI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IB26Wnpukpr5",
        "outputId": "fd03b9b1-4d62-4b77-e885-f905ac84c553"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello there!', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-d9417048-849f-4d2e-a7ce-36729b8b7d39-0', usage_metadata={'input_tokens': 3, 'output_tokens': 4, 'total_tokens': 7, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    max_retries=2,\n",
        "    api_key=gemini_api_key\n",
        ")\n",
        "\n",
        "llm.invoke(\"greet me\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9Gyb82sBWTO5"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    # Messages have the type \"list\". The `add_messages` function\n",
        "    # in the annotation defines how this state key should be updated\n",
        "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oU9Nk8ItZpJn",
        "outputId": "709376ff-4261-4d85-fdef-09b9237039ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update state 1: [HumanMessage(content='hello', additional_kwargs={}, response_metadata={}, id='32abe0cb-ffb0-4fec-9009-4d4fa7497607'), AIMessage(content='hello! there', additional_kwargs={}, response_metadata={}, id='09fb764e-d0f3-4713-9bf7-da8b6b7026b1')]\n"
          ]
        }
      ],
      "source": [
        "new_message_1 = [{\"role\": \"user\", \"content\": \"hello\"}]\n",
        "new_message_2 = [{\"role\": \"ai\", \"content\": \"hello! there\"}]\n",
        "\n",
        "message = add_messages(new_message_1, new_message_2)\n",
        "\n",
        "print(\"update state 1:\", message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmqQluQDr5zK",
        "outputId": "6cca6b90-cc12-4561-b68b-23af0b68bd1e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x79edcfef5b50>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "def chatbot(state: State):\n",
        "  return{\"messages\": [llm.invoke(state[\"messages\"])]}\n",
        "\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMn9kfSXs7r_",
        "outputId": "07b00f1a-64d9-41c3-e7cc-ed4d417e2996"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x79edcfef5b50>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "graph_builder.add_edge(START, \"chatbot\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gz-FhZmwtwJo",
        "outputId": "0f597db9-050e-4e45-b61d-29c9a6e68cc1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x79edcfef5b50>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "graph_builder.add_edge(\"chatbot\", END)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RsQHLiUugWDH"
      },
      "outputs": [],
      "source": [
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "5qOMHssVuUuT",
        "outputId": "7c2c649d-2c56-4127-b07d-43d036deb522"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "  display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOEsWigivR1b",
        "outputId": "c559d30f-bc51-43b5-fd8f-0a07f625a759"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'chatbot': {'messages': [AIMessage(content=\"It's nice to meet you, Junaid.  How can I help you today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-7c0f7ba3-6463-486b-9a6a-e12a1641c5e3-0', usage_metadata={'input_tokens': 6, 'output_tokens': 21, 'total_tokens': 27, 'input_token_details': {'cache_read': 0}})]}}\n",
            "EVENT: It's nice to meet you, Junaid.  How can I help you today?\n"
          ]
        }
      ],
      "source": [
        "for event in graph.stream({\"messages\": [(\"user\", \"i am junaid\")]}):\n",
        "  print(event)\n",
        "  print(\"EVENT:\", list(event.values())[0][\"messages\"][-1].content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qqpRrkvqXPBo"
      },
      "outputs": [],
      "source": [
        "def stream_graph_updates(user_input: str):\n",
        "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
        "        for value in event.values():\n",
        "            print(\"Assistant:\", value[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9G7ARRYgBf5",
        "outputId": "e02de859-2536-41de-8bbe-19fc647c304d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: q\n",
            "Goodbye!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        stream_graph_updates(user_input)\n",
        "    except:\n",
        "        # fallback if input() is not available\n",
        "        user_input = \"What do you know about LangGraph?\"\n",
        "        print(\"User: \" + user_input)\n",
        "        stream_graph_updates(user_input)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cEX_x3CSXTUQ"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U tavily-python langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "RUnhoVD6YmKY"
      },
      "outputs": [],
      "source": [
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EuOJM3zBZ7RP"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "search_tool = TavilySearchResults(max_results=2)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "PO3ho3Am0Nw4"
      },
      "outputs": [],
      "source": [
        "tools = [search_tool]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qknE-bULcFgc",
        "outputId": "795cdfc5-161f-4928-fbaa-4c74ea90c9a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'url': 'https://www.nbcnews.com/politics/2024-elections/president-results',\n",
              "  'content': \"Democrats won Nevada in the past two presidential elections — but polling and voting trends in the state have made it an appealing target for Donald Trump in a bid to flip states in his direction. North Carolina hasn’t voted for a Democrat for president since 2008, but Kamala Harris’ campaign has targeted it as a state she can win, buoyed by its large Black population. Resident of the states listed in the 'Your Rights' section of NBCUniversal’s Privacy Policy Only: To opt out of selling or sharing/processing for targeted advertising of information such as cookies and device identifiers processed for targeted ads (as defined by law) and related purposes for this site/app on this browser/device, switch this toggle to off (grey color) by moving it left and clicking “Confirm My Choice” below.\"},\n",
              " {'url': 'https://www.270towin.com/2024_Election/results',\n",
              "  'content': '2024 Electoral College Map 2024 Presidential Election Results 2024 Pundit Forecasts 2024 Polling Averages by State Most Recent General Election Polls 2024 Election Simulator 2024 Presidential Calendar Historical Elections 2026 Senate Interactive Map 2024 Senate Election Results 2024 Pundit Forecasts 2024 Senate Polls What Happens: 50-50 Senate Contact Your Senator 2025-26 Governor Interactive Map 2024 Governor Election Results 2024 Pundit Forecasts 2024 Governor Polls State Government Trifectas State Senate Interactive Map State House Interactive Map 2024 Election Results 2024 Primary Election Results The Republican ticket of Donald Trump, who was the 45th president of the United States, and JD Vance, the junior U.S. senator from Ohio defeated the Democratic ticket of Kamala Harris, the incumbent vice president, and Tim Walz, the 41st governor of Minnesota.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "search_tool.invoke(\"who is winner of 2024 un elections?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqnNl4ofeGwo",
        "outputId": "36708f81-f2b9-49ec-90ed-6d790e35e1c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x79edb7762510>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "from typing import Annotated\n",
        "\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "\n",
        "# llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
        "# Modification: tell the LLM which tools it can call\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0oKJmWbe88r",
        "outputId": "a7305bdc-f57e-4c0d-85c3-054f147db8f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatGoogleGenerativeAI(model='models/gemini-1.5-flash', google_api_key=SecretStr('**********'), max_retries=2, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x79ee112e99d0>, default_metadata=())"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lKEyafWfChR",
        "outputId": "e82ec1ed-8bac-45a7-e679-b183f08fac30"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RunnableBinding(bound=ChatGoogleGenerativeAI(model='models/gemini-1.5-flash', google_api_key=SecretStr('**********'), max_retries=2, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x79ee112e99d0>, default_metadata=()), kwargs={'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "llm_with_tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNVjYpW1hL-8",
        "outputId": "90cb19ee-db9e-4d7e-a13a-6d3d2bf1ad2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='I cannot answer this question. The available tools lack the functionality to access information about the US 2024 elections.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-ed447771-ecea-45e0-8dc4-28fa777c981e-0', usage_metadata={'input_tokens': 88, 'output_tokens': 26, 'total_tokens': 114, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "llm_with_tools.invoke(\"Search when is the us 2024 elections be happend\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "NLHYKcF2FgEQ"
      },
      "outputs": [],
      "source": [
        "tool_calls=[\n",
        "    {'name': 'tavily_search_results_json', 'args':\n",
        "     {'query': 'when is the us 2024 elections'}, 'id':\n",
        "     '782aab1e-9efb-4e07-816f-d5de72c13907', 'type':\n",
        "     'tool_call'}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uuvMMjDytcn",
        "outputId": "de1346f0-f457-49f5-8035-f8f9adfae7cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "{'tavily_search_results_json': TavilySearchResults(max_results=2, api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********')))}\n"
          ]
        }
      ],
      "source": [
        "tools_by_name = {tool.name: tool for tool in tools}\n",
        "print(type(tools_by_name))\n",
        "print(tools_by_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymItKD7izUC_",
        "outputId": "f03b9468-a6a0-4079-e2b7-e90b9a4142fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TavilySearchResults(max_results=2, api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********')))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "tools_by_name[\"tavily_search_results_json\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "A4bUkjQg0SpV"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "from langchain_core.messages import ToolMessage\n",
        "\n",
        "\n",
        "class BasicToolNode:\n",
        "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
        "\n",
        "    def __init__(self, tools: list) -> None:\n",
        "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
        "\n",
        "    def __call__(self, inputs: dict):\n",
        "        if messages := inputs.get(\"messages\", []):\n",
        "            message = messages[-1]\n",
        "        else:\n",
        "            raise ValueError(\"No message found in input...\")\n",
        "        outputs = []\n",
        "        for tool_call in message.tool_calls:\n",
        "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
        "                tool_call[\"args\"]\n",
        "            )\n",
        "            outputs.append(\n",
        "                ToolMessage(\n",
        "                    content=json.dumps(tool_result),\n",
        "                    name=tool_call[\"name\"],\n",
        "                    tool_call_id=tool_call[\"id\"],\n",
        "                )\n",
        "            )\n",
        "        return {\"messages\": outputs}\n",
        "\n",
        "\n",
        "tool_node = BasicToolNode(tools=[search_tool])\n",
        "# graph_builder.add_node(\"tools\", tool_node)      # second node (tool_node)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gk4vdQ1y2BTP",
        "outputId": "bf3a6a66-df65-4ea1-ef6b-b04ad0b5b96c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [ToolMessage(content='[{\"url\": \"https://usafacts.org/articles/dates-to-know-for-the-2024-presidential-election/\", \"content\": \"Explore more of USAFacts\\\\nRelated Articles\\\\nGovernment\\\\nThe October 2019 Democratic debate and the data behind it\\\\nGovernment\\\\nFor a nonpartisan state of the nation, try The State of the Union in Numbers\\\\nGovernment\\\\nData on six topics from the vice presidential debate\\\\nGovernment\\\\nData on four topics from the final presidential debate\\\\nRelated Data\\\\nVoting-age population during elections\\\\n255.46 million\\\\n2022\\\\nPercent of people who always or sometimes vote in local elections\\\\n56%\\\\n2013\\\\nNewsletter\\\\nData delivered to your inbox\\\\nKeep up with the latest data and most popular content.\\\\n \\\\u2022 Check your spelling\\\\n\\\\u2022 Try other search terms\\\\n\\\\u2022 Use fewer words\\\\nDates to know for the 2024 presidential election\\\\nThe 2024 presidential election will take place on Tuesday, November 5, 2024. All topics\\\\nExplore articles, data and trends by topic\\\\nAbout\\\\nWhat makes USAFacts different\\\\nWe frequently add data and we\\'re interested in what would be useful to people. Beginning in January of the election year, voters participate in primaries and caucuses, influencing which presidential candidates are on the November ballot.\\\\n When is the Republican National Convention?\\\\nThe Republican National Convention will take place from July 15-18, 2024, in Milwaukee.\\\\n\"}, {\"url\": \"https://en.wikipedia.org/wiki/2024_United_States_elections\", \"content\": \"On March 30, 2023, Trump was indicted by a grand jury in Manhattan for his alleged role in a scandal stemming from hush money payments made to Stormy Daniels before the 2016 presidential election.[8]\\\\nOn May 10, 2023, Republican New York Congressman George Santos was indicted on federal charges of fraud and money laundering.[9]\\\\nOn June 8, 2023, Trump was indicted on 37 federal charges related to his alleged mishandling of classified documents by the office of the Smith special counsel investigation.[10]\\\\nOn August 1, 2023, a Washington, D.C., federal grand jury indicted Trump again on four felony counts of conspiracy and obstruction related to Trump\\'s role in the January 6 attack and his efforts to overturn the 2020 election.[11]\\\\nOn August 14, a Georgia grand jury indicted Trump on racketeering and other felonies committed in an effort to overturn the state\\'s 2020 election results and the Trump\\\\u2013Raffensperger phone call.[12][13] Thus, many conservative political analysts and commentators called a continued Republican alliance with the anti-abortion movement \\\\\"untenable\\\\\" and an \\\\\"electoral disaster\\\\\", and urged the party to favor abortion rights.[6] Some issue polling has shown Donald Trump, the likely Republican nominee, outrunning his party and closing the gap with Democrats on the issue of abortion, but no election data with Trump directly on the ballot has happened to verify these results.[7]\\\\nIndictments[edit]\\\\nOn November 18, 2022, three days after former president and Republican candidate Donald Trump announced his 2024 re-election bid, U.S. Attorney General Merrick Garland appointed Jack Smith as special counsel to investigate Trump\\'s role in the January 6 U.S. Capitol attack and Trump\\'s mishandling of government documents, including classified documents.\\\\n Three Democratic-held seats up for election are in the heavily Republican-leaning states of Montana, Ohio, and West Virginia, all of which were won comfortably by Trump in both 2016 and 2020.[23] Other potential Republican targets include seats in Arizona, Michigan, Nevada, Pennsylvania, and Wisconsin, while Democrats may target Republican-held seats in Florida and Texas.[24]\\\\nTwo special elections are scheduled to fill the unexpired terms of senators who vacated their seats during the 118th Congress:\\\\nAll 435 voting seats in the United States House of Representatives will be up for election. On August 11, four months after incumbent president and Democratic candidate Joe Biden announced his re-election bid, Garland appointed David C. Weiss to serve as special counsel to investigate Biden\\'s son, Hunter Biden, who was indicted on September 14, 2023, on three federal firearms-related charges.[14][15]\\\\nOn September 22, 2023, Democratic U.S. Senator Bob Menendez of New Jersey and his wife Nadine were both indicted on bribery charges.[16][17]\\\\nFederal elections[edit]\\\\nPresidential election[edit]\\\\nThe 2024 United States presidential election will be the 60th quadrennial U.S. presidential election. The first Republican presidential debate was held on August 23, 2023, and the first scheduled primary contest is the 2024 Iowa Republican presidential caucuses, which will be held on January 15, 2024.[22]\\\\nCongressional elections[edit]\\\\nAll 33 seats in Senate Class 1 and one seat in Senate Class 2 will be up for election; at least one additional special election will take place to fill vacancies that arise during the 118th Congress.\"}]', name='tavily_search_results_json', tool_call_id='fb1f767e-00b1-4160-b594-c8e67317352c')]}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "\n",
        "messages = [\n",
        "    AIMessage(content='', additional_kwargs={'function_call': {'name': 'tavily_search_results_json', 'arguments': '{\"query\": \"when is the us 2024 elections\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-d43ad1dc-1e1a-4f6e-b299-1a01469673ca-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'when is the us 2024 elections'}, 'id': 'fb1f767e-00b1-4160-b594-c8e67317352c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 88, 'output_tokens': 19, 'total_tokens': 107, 'input_token_details': {'cache_read': 0}})\n",
        "\n",
        "\n",
        "\n",
        "]\n",
        "tool_node(inputs={\"messages\": messages})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "3WnYmWx4SRK0"
      },
      "outputs": [],
      "source": [
        "# from typing import Literal\n",
        "\n",
        "# def route_tools(\n",
        "#     state: State,\n",
        "# ):\n",
        "#     \"\"\"\n",
        "#     Use in the conditional_edge to route to the ToolNode if the last message\n",
        "#     has tool calls. Otherwise, route to the end.\n",
        "#     \"\"\"\n",
        "#     if isinstance(state, list):\n",
        "#         ai_message = state[-1]\n",
        "#     elif messages := state.get(\"messages\", []):\n",
        "#         ai_message = messages[-1]\n",
        "#     else:\n",
        "#         raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
        "#     if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
        "#         return \"tools\"\n",
        "#     return END\n",
        "\n",
        "\n",
        "# # The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"END\" if\n",
        "# # it is fine directly responding. This conditional routing defines the main agent loop.\n",
        "# graph_builder.add_conditional_edges(\n",
        "#     \"chatbot\",\n",
        "#     route_tools,\n",
        "#     # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node\n",
        "#     # It defaults to the identity function, but if you\n",
        "#     # want to use a node named something else apart from \"tools\",\n",
        "#     # You can update the value of the dictionary to something else\n",
        "#     # e.g., \"tools\": \"my_tools\"\n",
        "#     {\"tools\": \"tools\", END: END},\n",
        "# )\n",
        "# # Any time a tool is called, we return to the chatbot to decide the next step\n",
        "# graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "# graph_builder.add_edge(START, \"chatbot\")\n",
        "# graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "laXUimaUQ9tZ"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.messages import BaseMessage\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "\n",
        "tool = TavilySearchResults(max_results=2)\n",
        "tools = [tool]\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "tool_node = ToolNode(tools=[tool])\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    tools_condition,\n",
        ")\n",
        "# Any time a tool is called, we return to the chatbot to decide the next step\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.set_entry_point(\"chatbot\")\n",
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "74OMEBUlQ-7B",
        "outputId": "db0249de-6a07-4b70-fdb7-3d151b9f1470"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6-tAa2KRGZ3",
        "outputId": "ae2c5336-c991-4fd0-c7f2-36ba37a64432"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: q\n",
            "Goodbye!\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        stream_graph_updates(user_input)\n",
        "    except:\n",
        "        # fallback if input() is not available\n",
        "        user_input = \"What do you know about LangGraph?\"\n",
        "        print(\"User: \" + user_input)\n",
        "        stream_graph_updates(user_input)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "1hebALb-aHYn"
      },
      "outputs": [],
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "memory = MemorySaver()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uXFTcGKwaQC_",
        "outputId": "2911ed59-ace1-4c00-a3c4-b4f87daad533"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__abstractmethods__',\n",
              " '__aenter__',\n",
              " '__aexit__',\n",
              " '__annotations__',\n",
              " '__class__',\n",
              " '__class_getitem__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__enter__',\n",
              " '__eq__',\n",
              " '__exit__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__orig_bases__',\n",
              " '__parameters__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_abc_impl',\n",
              " '_is_protocol',\n",
              " 'aget',\n",
              " 'aget_tuple',\n",
              " 'alist',\n",
              " 'aput',\n",
              " 'aput_writes',\n",
              " 'config_specs',\n",
              " 'get',\n",
              " 'get_next_version',\n",
              " 'get_tuple',\n",
              " 'list',\n",
              " 'put',\n",
              " 'put_writes',\n",
              " 'serde',\n",
              " 'stack',\n",
              " 'storage',\n",
              " 'writes']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "dir(memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ei6po6XeaXjj",
        "outputId": "e6ad9681-3817-450a-b769-bd93b0308588"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x79edb774a150>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.messages import BaseMessage\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "\n",
        "tool = TavilySearchResults(max_results=2)\n",
        "tools = [tool]\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "tool_node = ToolNode(tools=[tool])\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    tools_condition,\n",
        ")\n",
        "# Any time a tool is called, we return to the chatbot to decide the next step\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(START, \"chatbot\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "8XJU5OeFaftl"
      },
      "outputs": [],
      "source": [
        "graph = graph_builder.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "0rCXllfHaoo1",
        "outputId": "772501b7-08eb-46e7-f8e6-04618a54cd47"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAANYAAAD5CAIAAADUe1yaAAAAAXNSR0IArs4c6QAAIABJREFUeJzt3XlYE9feB/AzScieAAk7kV0EBFdcQXEtda3Y1laxLq193G2va721ajdfa6v1tr3WtnrdsO4bWBVU1LrhjgooKgIKGAiEJCRkz7x/hIdSDJvNzJmQ83n6R80y54d+OTNz5swZDMdxgCDw0GAXgDg7FEEEMhRBBDIUQQQyFEEEMhRBBDIG7AJehUpuVFUZa1VmTY3JZHCMYSWGC0ZnYFwBnStkiH2ZbC4ddkVUgTnGPyAAAABZqa7grqYwV8MTMswmnCuk8wQMJocGHOEnYLAwdbWptsZcqzJplGaeKz04mtexG5/v7gK7NMgcI4LKKuOV1Eq6C+buxQzuzPPwZ8Gu6J8qLdAW5mjkUr2bJ7P/GDHDxXmPiBwggtdOVuXfrOk/1iOsKx92LfZ390/FlbSqAUke0f1dYdcCB9UjePA/JdFxwohYIexCiHU9XV4jNw6d6A27EAioG0Ecx39d/nTsTD/fYA7sWsiQd01VlKsZ+b4v7ELIRt0I/rz0yZQVQTyhQ56zv5qHN1Q5V1RvfSSBXQipKBrBgxtL4saJfYOcov9r6P5lZVWZftDbXrALIQ8VT8SyTlTFDBA6Yf4AADFxrlwB/cF1FexCyEO5CFZXGJ5kqzv1bOfnH83oMdT9/AEZ7CrIQ7kIXkmr6j9GDLsKmBgutJ7D3K+drIJdCEmoFUFpkY7FoYXEtMPxvzbpnSiSFumMBgvsQshArQgW3FOLfJikNZeTk6PX62F9vXlsHr0wR0PQximFWhEszNUEd+aR01ZaWtq0adO0Wi2Ur7coOJqHIki26gqDUMRw9yapF3zlDsw6jEVc/2cVEsNTVhkJbYIiKBRBZaURwzAitlxcXDxr1qz4+PiRI0euWbPGYrGkpaWtXbsWADBs2LDY2Ni0tDQAQHZ29rx58+Lj4+Pj42fOnPngwQPr1xUKRWxs7K5du1asWBEfH//hhx/a/Lp9MVxoaoVJozTZfctUQ6FrD7UqM1dIyCy6L7/8sqioaNGiRRqN5ubNmzQaLS4ubvLkySkpKRs3buTz+QEBAQCAsrIyvV4/Y8YMGo124MCBBQsWpKWlsdls60a2bt369ttvb968mU6ne3t7v/x1u+MJGRqViedKoX8jIlDox9OoTARdjisrK4uIiEhKSgIATJ48GQAgEokkEgkAIDo62s3NzfqxESNGjBw50vr/UVFRs2bNys7O7tu3r/WVmJiYuXPn1m/z5a/bHc+VrlGaQQeCNk8VFIogADiDRciOeOTIkdu3b1+3bt2MGTNEIlFTH8Mw7Ny5cykpKYWFhVwuFwBQVfXX4Fzv3r2JqK0ZLDYdt1Dx8ql9UehYkMNj1MgJOfSZO3fuwoULMzIyxo4du3///qY+tmXLliVLlkRFRW3YsOHjjz8GAFgsf43McThkXzBUVBq4TjBLg0IR5ArptSozEVvGMGzSpEnHjh1LSEhYt25ddnZ2/Vv1szT0ev22bdvGjRu3aNGibt26xcTEtGbLhE7yIO7gmFIoFEGByMWFmB2xdQCFx+PNmjULAPDw4cP6Xk0mq7saq9Vq9Xp9ZGSk9Y8KhaJRL9hIo68TQSBiCNzafy9IoZ/Q059V+kSrVpj49v57X7ZsGZ/P79u376VLlwAA1px17dqVTqd/9913Y8eO1ev1b775ZlhY2N69e8VisVqt/vXXX2k02pMnT5ra5stft2/NRXkaFyYNoxHyO0kp9NWrV8Ou4S8KmdGos3gFsO272ZKSkkuXLp06dUqr1c6fP3/QoEEAAKFQ6O3tffr06YsXL6pUqtGjR/fo0ePy5cv79+8vLi6eP39+YGDgoUOHkpOTjUbjzp074+Pjo6Ki6rf58tftW/Odcwr/MI5XBzv/VVAQtaasPnuoeZqjGfSWE03YbErar2WDJ3jy3dr/LZ4U2hEDAAIieNdOyqXFOp9A27/9CoVi3LhxNt+SSCQlJSUvv56QkPD555/bu9LGZsyYYXOvHRkZWX+VpaGePXuuX7++qa3lXFHy3RjOkD/K9YIAgNIn2munqsbPs33/hNlsLi8vt/kWhtn+WTgcjru7u73LbEwmkxmNNi7pNlUVi8USi5ucFvnr8qdTVwayOO3/dJiKEQQAnNtf0bE7X9KRC7sQOO5fVhp0lp5DCf+1oQgKDcrUGzzB69QOqVZNyBghxT3Lr316T+08+aNoBAEAE5cG/P7NM9hVkK2m2ng6pfyN2f6wCyEVFXfEVnqteffaZ8mfBDjJIVF5sS4jpTx5eQDNCcYCG6JuBK29wp51z8fO9PVp7zd05t9S3f1TOeFf7X1WjC2UjqDV2T3lWo05bowHaROqyVTyuPZyWpUkjBM31gN2LXA4QAQBAIU5mstplSExPO8AdnA0rx3sqnQac2Gu5kWhTllpjBsjtvsFIQfiGBG0enyn5vEddWGOJrKPkMHEeEIGz5XOYtMd4geg0zGNylSrMqmVJpXcVF6sC+7MC+8pCOjkpGNP9RwpgvWKHmiUFUaNyqRRmk0mi8WuozdGozEvL69r16723CgAHD4dt+BcIYPvyhD7Mv1C2/nRbes5ZAQJVVVVNXHixIyMDNiFOAuKjgsizgNFEIEMRbAxDMPCw8NhV+FEUAQbw3H80aNHsKtwIiiCjWEY5urqpIvfQ4Ei2BiO40qlEnYVTgRF0AYfHx/YJTgRFEEbpFIp7BKcCIpgYxiGNbxTDiEaimBjOI7n5eXBrsKJoAgikKEINoZhWDOrbyF2hyLYGI7jcrkcdhVOBEXQBg8PJ53ADAWKoA2VlZWwS3AiKIIIZCiCjWEYFhoaCrsKJ4Ii2BiO4wUFBbCrcCIogghkKII21C/3i5AARdAGmysCIgRBEUQgQxFsDM2UIRmKYGNopgzJUAQRyFAEG0M3cZIMRbAxdBMnyVAEEchQBBtD9xGTDEWwMXQfMclQBBtDM2VIhiLYGJopQzIUQQQyFEEbvL29YZfgRFAEbWjqSYsIEVAEbUDzBcmEImgDmi9IJhTBxtBkLZKhCDaGJmuRDEXQBonE9jPhESKgR9/U+eCDD6RSKZ1Ot1gs1dXVIpEIwzCTyXTixAnYpbVzqBesM2HChJqamrKyMqlUqtfrX7x4UVZWhmEO/7xF6kMRrJOYmBgSEtLwFRzHe/bsCa8iZ4Ei+JeJEydyuX89F9PHx2fSpElQK3IKKIJ/SUxMDAwMtP6/tQuMiIiAXVT7hyL4N1OmTOHxeNYucOLEibDLcQoogn8zfPjwwMBAHMe7d++OLtORgwG7gBboNObKMoNBbyGtxXGvzQS1R18fOPVpjoa0Rrk8usjPhcmik9YidVB3XNBswjNSpCWPtJJwnpHECEJh1Fvk5bqwboLBb3vBroVsFI2gXms+9ENpz0QPv2BuKz7eTjy4rigv0o750Bd2IaSiaAR3rSke/I6vqwcTdiFke5KtkhbWjpjmRA/Bo+LpSG6WMiiK74T5AwCEdRPiFlD2VAu7EPJQMYIVz/QcAdXPk4jjwqJVvTDAroI8VIygQWcRilxgVwGNmw9LozTBroI8VIygrtZiNsMuAh6zATcZqXiAThAqRhBxKiiCCGQogghkKIIIZCiCCGQogghkKIIIZCiCCGQogghkKIIIZCiCCGTtOYKPn+QPHhp79erFNn3LbDbfv5/d8JUVKxfNnDW5ra2/vB3EpvYcwVfz7fovN2xcQ53ttHsogo0Z9HpKbafdayczQ3U63a6ULefOZcgqK7y9fV8bPip50nTrW4VFBXv378zPz5NIAj6avywmphsAoKKifOu2TdeuXdZo1B06BE6aOH3Y0NcBAGvXrT53/jQAYPDQWADA77tTfX38AACaWs2q1Utv37nOZLKGDnn9g/fnsFgsAIDJZNq2fXN6xnGlUhEYGDxt6sz4uEEvb+fg/lNisQfsvySKag8RNJvN//704/s52eOT3g0LDS8qfvq8pJhOr7shMmX31glvvzfi9bG/79n+6WcLf09J5fP5JrPp4cPcN8a+5Sp0+/NS5tdrVvj7d4iM6Dx50vuyivIXL0qXf/IFAEAsqstNefmLfn0HzJ2z6MaNqwcO7i4te/71lxsAAN+t/+rM2ZOTk98PCgo9c/bkZysX/+f737p06d5oO66ublD/hiitPUTwwp9n72TfXLL4s5Ej3nj53Y/mL0tMHA0ACAwInjNv2q3b1xIGDvXz9d/+vwPWhbNGjHgj6c1hly+fj4zoLJEEuLq6yaurrJ1lvZDgsLlzFgIAXk8c4+Hhtf9Ayt27t93dRekZx6e8N2Pa1JkAgISBQydPSdq+45cN6zc3tR3kZe0hgtdvXGGxWImvjbb5rlBY90C5oKBQAIBMVrea/pOCR9t3/JKfn2ftR+XyqlY2lzTunf0HUu5k37TuW+PjB1tfxzCsV2zf02fQeoRt0x5OR6rlVR5iz/o9b1NoNJo1bQCA23duzJk71WgwLF2y6vNV64RCVwve2rvlPTw8AQAajVqjUQMA3N1E9W8Jha61tbUaDXnLMLQD7aEX5PMF8urW9mFWu3Zt8fOTrPl6I4PBAABw2JyG7zZ/b7VCUQ0AcHcXeXh4AQBUKqU1lAAAubyKwWCw2ezWbAexag+9YPfuvbRa7dnM9PpXTKYW7kBTqhRhoeHW/BkMhlptrcVS1wuy2Ry5vKr+jy+7cOEMAKBHj96RkdEYhmVdu2R93WAwZF271LlzF2t/3OJ2EKv20AsOHzby6LH9a79Z9fBhblho+NPCJ7duX/t18+5mvtKtW2x6etqJk8eEAtcDh3bX1KiKCgtwHMcwrGuXHidPpW74fk1MdDeBQNi//0AAQMHTx//dtCE0tGN+fl7a8cMJA4dGdIoCACS+Nnr7jl/MZrOfn+SPP47I5VX/Xv6ltYmG2/Hzk6Dzkqa0hwiyWKz1323+7bcfT585cfyPwz4+foMHvdZ8R/j+tNnyqsoff/pWIBCOHjV+wluTN2xccyf7Zo/uvYYPH5n/KC/j9B9Xsy6+njjGGsGJ707Nybl7/I/DPB7/7beSp0+bZd3Oxx99wuPxjxzdV1OjCg4KXfPV9z2697K+1XA7U977EEWwKVRcU+bY5rLwWDdJRyda0Kih3CsKk8EU/4azDGW3h2NBxKGhCCKQoQgikKEIIpChCCKQoQgikKEIIpChCCKQoQgikKEIIpChCCKQoQgikKEIIpBRcbKWUOxCo1Fu/g5p6AzMqZ6HSMVekMOjyUqc9z5waVGtUOxEj12hYgQDI7mqSid6/FAjWrU5IJzTig+2E1SMoG8wR+zHvJJaAbsQCE6nlPYc6sbkONGOmIqzpq1uZ1aXPdX5d+R5+rMZTCr+qtiRTm2qkurvX6oe8o5XQCfnmi5O3QgCAJ7la/JvqmtrzNXlf9svm81mo9FYf6+kfeE4rtPpOBySdoVarZbFYglFLE8Js/sgN6c6CqyDO6D58+cTt/GNGzfGx8enpqYS10RDFRUVK1euJKctaqJ0L/iyzMzMIUOGELf9Fy9ezJ8/v6ioKDIycteuXcQ19LKdO3cOHTrU39+fzEapwJGOsd555x2i/4UOHDhQVFQEAHj27Nnx48cJbauRkSNHzp49W+98qxI6Ri8olUpdXV1LS0vDwsKIa6W0tHTBggXFxcXWP5LfEVoPDe/duxcVFSUQCEhuGhYH6AUPHDiQlZXF4XAIzR8A4MiRI/X5AwAUFxcfO3aM0BZfxuFwOnbsOGbMGLVaTXLTsDhABIuLi8eNG0d0K2VlZefOnWv4ikaj2b27uVVBCCISic6fP6/T6aRSKfmtk4/SEbxy5QoAYPHixSS0tXfvXmsXWL8QEYZhz58/J6Fpmzw8PPh8flxcXMOOuX2CfUpum8Fg6N+/f3V1NflNy2Sy1157jfx2bdJqtdu2bYNdBbGo2AsqFIri4uKzZ8+6uUFYotlsNkdERJDfrk1sNnvatGkAgE8//dS6OGf7Q7kIpqamFhUVhYWFEXTxo0VGo9E6LkMp06dP//jjj2FXQQhqRVAmk925c6dbN5jroGm1Wm9vb4gF2BQWFvbjjz8CAM6fPw+7FjujUASLioowDFu1ahXcMqqqqlxcqHuh1mg0Ll26FHYV9kSVCK5cuZLD4Xh4wF9Ur7q6OiAgAHYVTRo+fPioUaNas5ixo6BEBEtKSvr06UOR3V9hYSEVfhOakZCQAADYt2/fo0ePYNdiB/AjqNVq+Xy+9TebCvR6fWhoKOwqWpacnLxq1ap2cJoMOYJLliy5evUqlMGXpmRmZoaHh8OuolX27NljMpny8/NhF/KPwIzgrVu3FixYQOjkq7ZSKBRCodDPzw92Ia3FYrHkcvnOnTthF/LqoEVQLpd37NixQ4cOsAqwKSsrKygoCHYVbdOvX7/q6mrYVbw6OBE8ePDgL7/8IhQKobTejD///HPgwIGwq2izjz76yGAwOOhcQwgRlEqlbm5uy5cvJ7/pFimVSkeMIACAyWRu2rQpJSUFdiFt5hhTVsmRnp5+4cKFNWvWwC7k1V27ds3Dw8Mhzujrkd0Lzps3Lycnh+RGW+nIkSNJSUmwq/hH+vTpExgY6FgPviM1ghcuXBgzZkx0dDSZjbZSYWEhg8Ho1asX7EL+KQaDMXz4cIVCAbuQ1kI74jqLFy8eNWrU4MGDYRdiB0ql8vjx48nJybALaRXyesF9+/ZRdhf88OHDFy9etI/8AQBcXV0dJX/kRbCoqGj//v3U3AUDAL7//ntybg8g05IlS+7evQu7ipaRFEEMw7Zs2UJOW2119OhRiUTSvXt32IXY2ZIlS3744QfYVbTM2Y8FTSZTYmLi2bNnYRfivMjoBTMzM7/44gsSGnoFCxcupGxtdpGRkQG7hBaQEcGsrKx+/fqR0FBb7dq1KyQkJC4uDnYhBHr06NG2bdtgV9Ec590RP378+Mcff3SIo6V/wmQypaWlUXnInYwIGgwGJpNJdCtt1bt376tXr9LpTrSeKTURviPOzc2dMWMG0a201eTJk3fs2OEk+cvJydm0aRPsKppEeATVajXRyxG11U8//ZScnBwZGQm7EJJER0fv3r1bp9PBLsQ2pzsW3LJli9FonD17NuxCSFVSUsLj8dzd3WEXYgPhvaDJZDIYqPIEh9TU1NLSUmfLHwBAIpFQM39kRDAzMxP63elWN27cyM3NpUgxJKuoqJgzZw7sKmwj/AFgYrGYCtPX7t27t2nTJoqPkBHHy8srPz9foVBQ6mZFK6c4FiwoKFi+fPn+/fthFwKTxWLBMAzDMNiFNNb+xwVLSkoWLFhw+PBhWAUgzSPjAl1SUhKsNWsfP348Z84clD/rqdjPP/8MuwobyHgY7KBBg6ZOnWo2m1UqlZeXF2kPU3j48OHevXtTU1PJaY7iBAJBQUEB7CpsIDCCAwcOrK2tta4lbD0EwXE8KiqKuBYbKigo+PTTTw8dOkROc9Q3YMCArl27wq7CBgJ3xEOGDKHRaNb5qtZXWCxWnz59iGuxXk5Ozm+//Yby1xCDwRCJRLCrsIHACK5evToqKqrh6Y6npycJv4jZ2dnffvvt2rVriW7IschkstGjR8OuwgZiT0e++eab+iVacBzncrlEXy++ePHi8ePHd+zYQWgrjojJZFqPi6iG2Ah6e3v/61//sq4YiWEY0V1genr6oUOHVqxYQWgrDkooFFLz9h3CB2Xi4+PHjx/P4/H4fD6hB4JHjx69cOHCxo0biWvCoWEYFhISArsKG1p1RmwyWrTqV7/INvHt94sLKgoKCkICOtdUE7JC8rlz53LvP3Xo5WCIZjQa33rrLfKfqteiFq6OPLiuundRKZcaOPx/NLuzflyGIAaDwcufX1ZQG9KF32u4u9iPRVxbjmXJkiVnz56tHxSzdoc4jt++fRt2aXWa6wWvZ8gry4wDxvsIRNR9CEJDFjOukBlObJcOm+TtGwTnyTlUM3v27Ly8vPLy8oajY5RaxrPJY8Frp+RKmWlAkrej5A8AQKNjIh/WuLmBZ/dUlD+j6CRhkoWEhPTs2bPhvg7DMEqtoWg7gtUVhspSfd/RXqTXYx9DJvrezHDgtW/ta8qUKQ0fqCGRSN59912oFf2N7QhWlupxnHKzelpP4O7y/HGtQQ9/niIVhIWF9e7d2/r/OI4PGDCAIo94sbIdQbXS7NnBsY+lAqN48hcOufYyEd577z0vLy8AgL+/P9UW3bIdQaPeYtQ5dheiqjIB4MAduX2Fhob26dMHx/GEhARKdYEkTdZC2spiwZ89rFVXmzQqk8mIazV2eMRSV7/Juu4dO4nizuwp/+dbY3PoTA6NK6QL3V0CIrj/ZFMogtTy4Loq/5a65HGtX7jQZMDpLnSaCwNg9hiUoLF79xtltACjPS4U16hxs9FkNhldXPSpv5QFRvHCu/M7xQpeYVMoglSRd0116VilZ4CAwRNED6fWvrJ57oGimora3Fu6y2lVA8aJO3ZvWxBRBOHTqs0ntpUbzbSQPhIG0/HWGMEwTOjNA4DH9xTezJQ/uKEe9YEPnd7aA3H4T+J0cs/yNTu/Lub7i3w6eTpi/hpichi+UV5Md7fNSwsqnrf20gCKIEzlz3UXDss7DQxkcRzmElSL2Hxm52HBJ7aVq6patYoGiiA0hbnqjBRZh24O89TPNgnqJTm8SSotbrkvRBGEQ60wnd3TbvNnFRTrf/jHUpOxhQFmFEE4Tu0sD+rtD7sKwoX29fvjfy0MQ6IIQnDzdLUZMBkujn3y0RosHlOjwXKvKpv5DIogBFknqrzCKLrUmt15hYgup8mb+YA9I5j3IOcfPpX5/IUzg4fGPntWZL+iKOfWGbl/lIiCywsBAL5YN/rgMTvf/Mpg0cUBgpwrTXaEdovgqfS0ufOm6XRae22wvXpwQ812dexZSG3F4rMf3lQ39a7dIuigT6UnmUpu1GksHIFz3drCF3Nkz3XGJqZv2ucC3an0tI3/WQsAGDd+GABg2dJVryeOAQBkZPyxe8+2srISsdhj1Mik5EnTrUt8mEymbds3p2ccVyoVgYHB06bOjI8b9PJms7Iu/brlx7KyEh8fv7Fj3hqf9I5dqoXoeX6tu4RP0MafPL114vSmMukjAV8UFhw7YvhsocADALDi66FvjlmW8+B8Xv5lDpvft1fSa4PrnoFgNpvPnN+adfOowaANDelpNBJ1t4NHkKD4QW1YNxs/u316wT694ya8PRkA8H9fb/xh45Y+veMAAOnpx//vm1UdO0Z8tmLNoITh/9v28+7f6xY5/W79V/v27xo9KunTf3/l4+P32crF9+7dabTN2tra1V8sY7owFy1c0b/fwKoqmV1KhavyhRHHCTkFfFxw47edC7y9gieM+3Rg/0lPi+5s3jbXYKiL1N7Dn/v5hM/5YHOPriMyMn/Ly79sff3I8W9Pn98aEd4/afRipgtbq6shojYAgNmMVctsXyyxTy/o7i7y85MAACIjo11d3awTxLf8778xMd1W/PsrAMDAAUNqalR79+14c/zEysqK9IzjU96bMW3qTABAwsChk6ckbd/xy4b1mxtus1oh1+v1AwYMGT5shF2KpAKN0sRgcYjY8tE/1veNTUoaXfdI2/CwPt/+8E7+k6yYqEEAgN49xg5NmAYA8PMJv37r2KMnWVGd4krKHmbdPDI0YfqIYbMAALHdRxUUEnVnpwuLoW7iFnKiZsqUlDyrrJS9M+G9+ld69ep34uSxktJn+fl5AID4+LrnT2MY1iu27+kzJxptwc/Xv3PnLim7t7LZnDGjx1Pw+U2vQKs2s9ztPxwor35RLiuslD/Punm04esKZd2wMJNZl3s6ne4q9FKqZACA+3nnAQAD+0+s/zyGETVIx2DRalXkRlCtUQMA3Nz+Wk1MIBACACplFRqNGgDg3uAtodC1trZWo9E03AKGYWvX/LBl60+bf9l44GDK8mVfdO3ag6BqSUPQqso16ioAwPDBM7pE/e3B8gKBx8sfptEYFosZAKBQSNlsPo/rSkhNjeCYpYmf3c6pr79f1cvTGwCgVCrq36qulluD6OHhBQBQqf4aKJLLqxgMBpvdeKiCz+d//NEnO7Yf4vH4Kz5bSM2FodqE50o36e0wC78RDlsAADAa9V6eQQ3/47CbO/Xh8dx1OrXRRMZTYUx6k8Dddn9ntwhy2BwAQGVl3UmDWOzh4+17/frl+g9cuHCGzWaHhXWKjIzGMCzr2iXr6waDIevapc6du9DpdKYLs2E6rQM9fr7+45PeVWvUUmmZvaqFReDKMBnsH0FPjwA3V58bt9P0hrpxWbPZZDIZm/+WxD8CAHDnXrrd63mZyWAWuNmOIH316tUvv1paoDWbgE9QGw6c2RzusdQDRcVPMYDlPbjfqVOUgC/cdyBFJis3Go2Hj+w9c/Zk8qT3e8X2FQqEUumLI0f3AYBVVsp+/vn7wqKCJYtX+vr6M1xcjhzd9zA/NyAgyEPsOWXa+MpKWVVV5ZGj+wx6/Qfvz2EwWnvk8PiOKiiSy2/ix4ZFrTRWSU0cNzufkWAY5u7me/1Wat7DizjAi5/fP3J8vdlsCOwQAwDIvLhT4hfRKaxuWbOsG0fZbF73Lq95eQTfyz17684JrU6t1lRfvXGkoPCmxC8yKiLevuUBAHRKTXAUW+Rt44DebhEUCoSent7nz5++evViTY0qMXF0WFi4u7so81zGyVOpimr5pEnTJye/b70w1Su2n0ajPnnqWGZmOo/LW7xoRa9e/QAAAr7A18fv9p0bNIwWGRVTUvLs0uVzFy9lisWenyxd7e8vaX091IwgV8i4/kelOND+h1/enkES/6inRdm3sk88K8n19Q3r2W2EdVywqQjSaLTI8HhZZfG93LNPi7J9vELk1WXensFERLDwVvmwZG8azcZlSdsra11Plxt0oOsgKi5N3EontpYkjPfwod7iRr+ve+4WIOa6OtEFkprKWpOqJmmu7cmR1OoknEFUX/6TXG0zEXz05PrOfctffp04rLhKAAACv0lEQVTDFjQ1dDw6cX7f2HH2qvBB/uXdB1e+/DqO4wDgNgduZk3/r8QvoqkN6tX6zr15Tb2LIki2bgPdrx4vcJcI6Qzb54JBAV0Wztn18us4DpqaXsPl2HPPHhrc02YBFosFx3GbzxEXCjyb2ppBa1RJ1ZG9mlxODkUQgrgx4rxbcp9ONgbtAABMJlvEhDmh374FVD6tHjBO3MwH0JRVCLoMcOOwzXptC4Mm7YCuRu8mxpq/uR1FEI4R032eZpXCroJYFgv+9HrZyOk+zX8MRRAOJos2brZf4fX2nMKnWSUTlwa0+DEUQWh8gznj5/kUXi+BXYj9mU2Wx5efTVomcfdqeXIJiiBMrmLmmBk+ORmFWlX7WRlbU617fOnZOwslXH6rTnZRBCHz8GfN3RBqUatKc8r1GjJmDBBHq9I/v/vCxaKe9U2osNWr5KNBGfgwDBv1gW9hjubPIxVcNzaDyxJ6cumOc5exSW9WyTRmvcGo0Q8a79EhvG0rXqIIUkVwNC84mldwX/34jubJZblIwjXqLXQmg8FiUHDFYhzHzXqT2WhyYdKqpdrgaF7HOH5Q1Kssi4giSC2hMfzQGD4A4EWhVqM0a5Qmg96is8dCv/bF4tLYXCZXyBW4070DWhh2aR6KIEX5BhNyiwkF2Y4gk41ZqNf5t4mrpwthN0Ig9mT7X0ng7iIrdux1EQrvqcW+7eGOp3bPdgS9OrAoueZJaylkhqDOXIYL6gYdQJO9oH8Y+89DUtLrsY+zu8v6jmxudgZCHc09jzj3qvJxtrprgtjdm9nU5DZK0apNykrjnwelb873d2vFpSGEClp4JHZhrib7gkJaqKMzqL5jFvmylDJDSDS39wgxT4jO9B1GCxGsp9dS/ZF0OA7YXAfoqpFGWhtBBCEI6jYQyFAEEchQBBHIUAQRyFAEEchQBBHI/h9Zsek9tetkAQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "X0oFD6B5auUT"
      },
      "outputs": [],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"1\"}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muTo3zpoa1Ca",
        "outputId": "4ba4cb75-5cf3-402c-f81d-3641a2e281a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Hi there! My name is Will.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Nice to meet you, Will! How can I help you today?\n"
          ]
        }
      ],
      "source": [
        "user_input = \"Hi there! My name is Will.\"\n",
        "\n",
        "# The config is the **second positional argument** to stream() or invoke()!\n",
        "events = graph.stream(\n",
        "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
        ")\n",
        "for event in events:\n",
        "    event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo3imUJRLWdZ",
        "outputId": "565372c4-bd56-4db6-e4d3-f1cc122a8a05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StateSnapshot(values={'messages': [HumanMessage(content='Hi there! My name is Will.', additional_kwargs={}, response_metadata={}, id='615439a8-d6a3-4789-88bd-6c26a51af907'), AIMessage(content='Nice to meet you, Will! How can I help you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-37a95558-700e-4739-b628-293e5303da01-0', usage_metadata={'input_tokens': 82, 'output_tokens': 15, 'total_tokens': 97, 'input_token_details': {'cache_read': 0}})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efe142b-1a20-6692-8001-8dc29fddb7c3'}}, metadata={'source': 'loop', 'writes': {'chatbot': {'messages': [AIMessage(content='Nice to meet you, Will! How can I help you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-37a95558-700e-4739-b628-293e5303da01-0', usage_metadata={'input_tokens': 82, 'output_tokens': 15, 'total_tokens': 97, 'input_token_details': {'cache_read': 0}})]}}, 'thread_id': '1', 'step': 1, 'parents': {}}, created_at='2025-02-02T08:50:03.605122+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efe142b-160c-6552-8000-cc9f67488b63'}}, tasks=())"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "snapshot = graph.get_state(config)\n",
        "snapshot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cig7xoqKbqc8",
        "outputId": "2a06f8be-9a52-4c6f-84d8-26eec9a8dab0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x79edd80c8110>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import StateGraph, START\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "memory = MemorySaver()\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "\n",
        "tool = TavilySearchResults(max_results=2)\n",
        "tools = [tool]\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "tool_node = ToolNode(tools=[tool])\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    tools_condition,\n",
        ")\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(START, \"chatbot\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "RGyAy5l2dEfQ"
      },
      "outputs": [],
      "source": [
        "graph = graph_builder.compile(\n",
        "    checkpointer=memory,\n",
        "    # This is new!\n",
        "    interrupt_before=[\"tools\"],\n",
        "    # Note: can also interrupt __after__ tools, if desired.\n",
        "    # interrupt_after=[\"tools\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPpfN6OndVna",
        "outputId": "ae24551b-c6cc-455e-c2ea-85ac523715db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "I AM LEARNING LANGGRAPH, COULD YOU SEARCH ON IT FOR ME\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (1e42cbd6-9f37-4972-b8c7-ddf71f648caa)\n",
            " Call ID: 1e42cbd6-9f37-4972-b8c7-ddf71f648caa\n",
            "  Args:\n",
            "    query: LangGraph\n"
          ]
        }
      ],
      "source": [
        "user_input = \"I AM LEARNING LANGGRAPH, COULD YOU SEARCH ON IT FOR ME\"\n",
        "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
        "# The config is the **second positional argument** to stream() or invoke()!\n",
        "events = graph.stream(\n",
        "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
        ")\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NtAuY3jMinPi",
        "outputId": "76357b02-eda6-4ece-db30-bdb84d9b4ea3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['InputType',\n",
              " 'OutputType',\n",
              " '__abstractmethods__',\n",
              " '__annotations__',\n",
              " '__class__',\n",
              " '__class_getitem__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__or__',\n",
              " '__orig_bases__',\n",
              " '__parameters__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__ror__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_abatch_with_config',\n",
              " '_abc_impl',\n",
              " '_acall_with_config',\n",
              " '_aprepare_state_snapshot',\n",
              " '_atransform_stream_with_config',\n",
              " '_batch_with_config',\n",
              " '_call_with_config',\n",
              " '_defaults',\n",
              " '_is_protocol',\n",
              " '_prepare_state_snapshot',\n",
              " '_repr_mimebundle_',\n",
              " '_transform_stream_with_config',\n",
              " 'abatch',\n",
              " 'abatch_as_completed',\n",
              " 'aget_graph',\n",
              " 'aget_state',\n",
              " 'aget_state_history',\n",
              " 'aget_subgraphs',\n",
              " 'ainvoke',\n",
              " 'as_tool',\n",
              " 'assign',\n",
              " 'astream',\n",
              " 'astream_events',\n",
              " 'astream_log',\n",
              " 'atransform',\n",
              " 'attach_branch',\n",
              " 'attach_edge',\n",
              " 'attach_node',\n",
              " 'aupdate_state',\n",
              " 'batch',\n",
              " 'batch_as_completed',\n",
              " 'bind',\n",
              " 'builder',\n",
              " 'channels',\n",
              " 'checkpointer',\n",
              " 'config',\n",
              " 'config_schema',\n",
              " 'config_specs',\n",
              " 'config_type',\n",
              " 'copy',\n",
              " 'debug',\n",
              " 'get_config_jsonschema',\n",
              " 'get_graph',\n",
              " 'get_input_jsonschema',\n",
              " 'get_input_schema',\n",
              " 'get_name',\n",
              " 'get_output_jsonschema',\n",
              " 'get_output_schema',\n",
              " 'get_prompts',\n",
              " 'get_state',\n",
              " 'get_state_history',\n",
              " 'get_subgraphs',\n",
              " 'input_channels',\n",
              " 'input_schema',\n",
              " 'interrupt_after_nodes',\n",
              " 'interrupt_before_nodes',\n",
              " 'invoke',\n",
              " 'map',\n",
              " 'name',\n",
              " 'nodes',\n",
              " 'output_channels',\n",
              " 'output_schema',\n",
              " 'pick',\n",
              " 'pipe',\n",
              " 'retry_policy',\n",
              " 'step_timeout',\n",
              " 'store',\n",
              " 'stream',\n",
              " 'stream_channels',\n",
              " 'stream_channels_asis',\n",
              " 'stream_channels_list',\n",
              " 'stream_eager',\n",
              " 'stream_mode',\n",
              " 'transform',\n",
              " 'update_state',\n",
              " 'validate',\n",
              " 'with_alisteners',\n",
              " 'with_config',\n",
              " 'with_fallbacks',\n",
              " 'with_listeners',\n",
              " 'with_retry',\n",
              " 'with_types']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "dir(graph)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bER96FZpihTX",
        "outputId": "eacc2533-8b75-4ef7-9c29-1d246b1f7367"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StateSnapshot(values={'messages': [HumanMessage(content='Hi there! My name is Will.', additional_kwargs={}, response_metadata={}, id='615439a8-d6a3-4789-88bd-6c26a51af907'), AIMessage(content='Nice to meet you, Will! How can I help you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-37a95558-700e-4739-b628-293e5303da01-0', usage_metadata={'input_tokens': 82, 'output_tokens': 15, 'total_tokens': 97, 'input_token_details': {'cache_read': 0}})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efe142b-1a20-6692-8001-8dc29fddb7c3'}}, metadata={'source': 'loop', 'writes': {'chatbot': {'messages': [AIMessage(content='Nice to meet you, Will! How can I help you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-37a95558-700e-4739-b628-293e5303da01-0', usage_metadata={'input_tokens': 82, 'output_tokens': 15, 'total_tokens': 97, 'input_token_details': {'cache_read': 0}})]}}, 'thread_id': '1', 'step': 1, 'parents': {}}, created_at='2025-02-02T08:50:03.605122+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efe142b-160c-6552-8000-cc9f67488b63'}}, tasks=())"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "snapshot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8krJ0icsiK3",
        "outputId": "b804e789-bee9-4c84-cc5d-6275df25b6ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'configurable': {'thread_id': '1',\n",
              "  'checkpoint_ns': '',\n",
              "  'checkpoint_id': '1efe142b-1a20-6692-8001-8dc29fddb7c3'}}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "snapshot.config     # current state     thread id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "2WPJWHnQsCRN"
      },
      "outputs": [],
      "source": [
        "snapshot = graph.get_state(config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MltdYxLQPl3c",
        "outputId": "69904884-27a5-499b-d5a7-d80ae25de1fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StateSnapshot(values={'messages': [HumanMessage(content='I AM LEARNING LANGGRAPH, COULD YOU SEARCH ON IT FOR ME', additional_kwargs={}, response_metadata={}, id='e505a195-e979-4e0b-900e-d054ff6218ba'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'tavily_search_results_json', 'arguments': '{\"query\": \"LangGraph\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-bb5e7659-db5e-4641-ad45-99ef480549e4-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'LangGraph'}, 'id': '1e42cbd6-9f37-4972-b8c7-ddf71f648caa', 'type': 'tool_call'}], usage_metadata={'input_tokens': 87, 'output_tokens': 11, 'total_tokens': 98, 'input_token_details': {'cache_read': 0}})]}, next=('tools',), config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1efe142b-2029-627f-8001-1ba5695ff4fb'}}, metadata={'source': 'loop', 'writes': {'chatbot': {'messages': [AIMessage(content='', additional_kwargs={'function_call': {'name': 'tavily_search_results_json', 'arguments': '{\"query\": \"LangGraph\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-bb5e7659-db5e-4641-ad45-99ef480549e4-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'LangGraph'}, 'id': '1e42cbd6-9f37-4972-b8c7-ddf71f648caa', 'type': 'tool_call'}], usage_metadata={'input_tokens': 87, 'output_tokens': 11, 'total_tokens': 98, 'input_token_details': {'cache_read': 0}})]}}, 'thread_id': '3', 'step': 1, 'parents': {}}, created_at='2025-02-02T08:50:04.237850+00:00', parent_config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1efe142b-1b3e-6b61-8000-496c64edfc1b'}}, tasks=(PregelTask(id='620867c5-cda5-871a-1069-80910dd33a16', name='tools', path=('__pregel_pull', 'tools'), error=None, interrupts=(), state=None, result=None),))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "snapshot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSzcByQNPZkK",
        "outputId": "7cedc414-ffa5-4f27-9926-20ca88e0ad52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tools',)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "snapshot.next       # to check next node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seH4f1aitNVF",
        "outputId": "cce984cd-ab0c-4665-89ef-1ec9c1fbd21f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='I AM LEARNING LANGGRAPH, COULD YOU SEARCH ON IT FOR ME', additional_kwargs={}, response_metadata={}, id='e505a195-e979-4e0b-900e-d054ff6218ba'),\n",
              "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'tavily_search_results_json', 'arguments': '{\"query\": \"LangGraph\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-bb5e7659-db5e-4641-ad45-99ef480549e4-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'LangGraph'}, 'id': '1e42cbd6-9f37-4972-b8c7-ddf71f648caa', 'type': 'tool_call'}], usage_metadata={'input_tokens': 87, 'output_tokens': 11, 'total_tokens': 98, 'input_token_details': {'cache_read': 0}})]}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "snapshot.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgX48rxGtWzo",
        "outputId": "1ab2bc39-07f1-4fa5-ae0f-b6b5c3905170"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='I AM LEARNING LANGGRAPH, COULD YOU SEARCH ON IT FOR ME', additional_kwargs={}, response_metadata={}, id='e505a195-e979-4e0b-900e-d054ff6218ba'),\n",
              " AIMessage(content='', additional_kwargs={'function_call': {'name': 'tavily_search_results_json', 'arguments': '{\"query\": \"LangGraph\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-bb5e7659-db5e-4641-ad45-99ef480549e4-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'LangGraph'}, 'id': '1e42cbd6-9f37-4972-b8c7-ddf71f648caa', 'type': 'tool_call'}], usage_metadata={'input_tokens': 87, 'output_tokens': 11, 'total_tokens': 98, 'input_token_details': {'cache_read': 0}})]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "snapshot.values['messages']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59s6CbPds9te",
        "outputId": "e8a32410-9fbd-43c8-abad-0ed54f025da2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (1e42cbd6-9f37-4972-b8c7-ddf71f648caa)\n",
            " Call ID: 1e42cbd6-9f37-4972-b8c7-ddf71f648caa\n",
            "  Args:\n",
            "    query: LangGraph\n"
          ]
        }
      ],
      "source": [
        "existing_message = snapshot.values[\"messages\"][-1]\n",
        "existing_message.pretty_print()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZB44FGQuLnC",
        "outputId": "3dd329f7-4471-4115-c558-f849f8506c41"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'tavily_search_results_json',\n",
              "  'args': {'query': 'LangGraph'},\n",
              "  'id': '1e42cbd6-9f37-4972-b8c7-ddf71f648caa',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "existing_message.tool_calls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3k64GXAt9OQ",
        "outputId": "9cda1612-38b7-4ab1-cd97-08af0e6f0818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (1e42cbd6-9f37-4972-b8c7-ddf71f648caa)\n",
            " Call ID: 1e42cbd6-9f37-4972-b8c7-ddf71f648caa\n",
            "  Args:\n",
            "    query: LangGraph\n"
          ]
        }
      ],
      "source": [
        "existing_message = snapshot.values[\"messages\"][-1]\n",
        "existing_message.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6UzIEgGtryU",
        "outputId": "63a17e48-5b75-45a3-8fe5-7d15938d1583"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'tavily_search_results_json',\n",
              "  'args': {'query': 'LangGraph framework for building language model applications'},\n",
              "  'id': 'toolu_01R4ZFcb5hohpiVZwr88Bxhc',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "[{'name': 'tavily_search_results_json',\n",
        "  'args': {'query': 'LangGraph framework for building language model applications'},\n",
        "  'id': 'toolu_01R4ZFcb5hohpiVZwr88Bxhc',\n",
        "  'type': 'tool_call'}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrQSUMNV3Jn1",
        "outputId": "25f36eae-c070-4c76-92d4-ebd6fa094dd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (1e42cbd6-9f37-4972-b8c7-ddf71f648caa)\n",
            " Call ID: 1e42cbd6-9f37-4972-b8c7-ddf71f648caa\n",
            "  Args:\n",
            "    query: LangGraph\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search_results_json\n",
            "\n",
            "[{\"url\": \"https://langchain-ai.github.io/langgraph/\", \"content\": \"Overview¶. LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. Check out an introductory tutorial here.. LangGraph is inspired by Pregel and Apache Beam.The public interface draws inspiration from NetworkX.LangGraph is built by LangChain Inc, the creators of LangChain, but can be used without LangChain.\"}, {\"url\": \"https://www.datacamp.com/tutorial/langgraph-tutorial\", \"content\": \"LangGraph is a library within the LangChain ecosystem that simplifies the development of complex, multi-agent large language model (LLM) applications. Learn how to use LangGraph to create stateful, flexible, and scalable systems with nodes, edges, and state management.\"}]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows.  It's part of the LangChain ecosystem and is inspired by Pregel and Apache Beam.  You can find more information and tutorials online.\n"
          ]
        }
      ],
      "source": [
        "# `None` will append nothing new to the current state, letting it resume as if it had never been interrupted\n",
        "events = graph.stream(None, config, stream_mode=\"values\")\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "h99cSzX2TCwq"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import StateGraph, START\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "\n",
        "tool = TavilySearchResults(max_results=2)\n",
        "tools = [tool]\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "tool_node = ToolNode(tools=[tool])\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    tools_condition,\n",
        ")\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "memory = MemorySaver()\n",
        "graph = graph_builder.compile(\n",
        "    checkpointer=memory,\n",
        "    # This is new!\n",
        "    interrupt_before=[\"tools\"],\n",
        "    # Note: can also interrupt **after** actions, if desired.\n",
        "    # interrupt_after=[\"tools\"]\n",
        ")\n",
        "\n",
        "user_input = \"I'm learning LangGraph. search on it for me?\"\n",
        "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
        "# The config is the **second positional argument** to stream() or invoke()!\n",
        "events = graph.stream({\"messages\": [(\"user\", user_input)]}, config)\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "H8_tOehOU0p3"
      },
      "outputs": [],
      "source": [
        "snapshot = graph.get_state(config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpYgY2bdVKe1",
        "outputId": "f4022468-a5c6-4146-e896-a1e106581d95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StateSnapshot(values={'messages': [HumanMessage(content=\"I'm learning LangGraph. search on it for me?\", additional_kwargs={}, response_metadata={}, id='46f0eac7-149f-42f9-9ac2-afce1d196710'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'tavily_search_results_json', 'arguments': '{\"query\": \"LangGraph\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-760259b1-bc9a-4a95-b5c1-f9fb30015f16-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'LangGraph'}, 'id': '127bf7bb-986b-4aa3-8e08-1bb168ee165e', 'type': 'tool_call'}], usage_metadata={'input_tokens': 87, 'output_tokens': 11, 'total_tokens': 98, 'input_token_details': {'cache_read': 0}})]}, next=('tools',), config={'configurable': {'thread_id': '4', 'checkpoint_ns': '', 'checkpoint_id': '1efe142b-454b-67ef-8001-11da006db835'}}, metadata={'source': 'loop', 'writes': {'chatbot': {'messages': [AIMessage(content='', additional_kwargs={'function_call': {'name': 'tavily_search_results_json', 'arguments': '{\"query\": \"LangGraph\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-760259b1-bc9a-4a95-b5c1-f9fb30015f16-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'LangGraph'}, 'id': '127bf7bb-986b-4aa3-8e08-1bb168ee165e', 'type': 'tool_call'}], usage_metadata={'input_tokens': 87, 'output_tokens': 11, 'total_tokens': 98, 'input_token_details': {'cache_read': 0}})]}}, 'thread_id': '4', 'step': 1, 'parents': {}}, created_at='2025-02-02T08:50:08.131617+00:00', parent_config={'configurable': {'thread_id': '4', 'checkpoint_ns': '', 'checkpoint_id': '1efe142b-4098-6355-8000-71cb3f25becc'}}, tasks=(PregelTask(id='0fb49851-c466-7536-2ad9-8f0a1c509cda', name='tools', path=('__pregel_pull', 'tools'), error=None, interrupts=(), state=None, result=None),))"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "snapshot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOCSNXtWVABo",
        "outputId": "668fe870-717c-407d-91c5-0acdb0977f1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (127bf7bb-986b-4aa3-8e08-1bb168ee165e)\n",
            " Call ID: 127bf7bb-986b-4aa3-8e08-1bb168ee165e\n",
            "  Args:\n",
            "    query: LangGraph\n"
          ]
        }
      ],
      "source": [
        "existing_message = snapshot.values[\"messages\"][-1]\n",
        "existing_message.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "BbYknNo2hhV6"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import AIMessage, ToolMessage\n",
        "\n",
        "tavily_answer = (\n",
        "    \"LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows.  It's part of the LangChain ecosystem and draws inspiration from Pregel and Apache Beam.  You can find more information and tutorials online.\"\n",
        ")\n",
        "new_messages = [\n",
        "    ToolMessage(content=tavily_answer, tool_call_id=existing_message.tool_calls[0][\"id\"]),\n",
        "    AIMessage(content=tavily_answer),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYC3TJythm2b",
        "outputId": "9af8c198-430f-45d5-a081-02bb7d55c418"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows.  It's part of the LangChain ecosystem and draws inspiration from Pregel and Apache Beam.  You can find more information and tutorials online.\n"
          ]
        }
      ],
      "source": [
        "new_messages[-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vriknEvhwcm",
        "outputId": "e11908c9-0d71-4374-f68c-f3364dc757d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\n",
            "LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows.  It's part of the LangChain ecosystem and draws inspiration from Pregel and Apache Beam.  You can find more information and tutorials online.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows.  It's part of the LangChain ecosystem and draws inspiration from Pregel and Apache Beam.  You can find more information and tutorials online.\n"
          ]
        }
      ],
      "source": [
        "for m in new_messages:\n",
        "  m.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsmN1dQeiMbt",
        "outputId": "ee8020ba-bbd0-45ae-9611-682fa72666de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'configurable': {'thread_id': '4',\n",
              "  'checkpoint_ns': '',\n",
              "  'checkpoint_id': '1efe142b-479b-687f-8002-eec311e5f485'}}"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "\n",
        "\n",
        "graph.update_state(\n",
        "    config,\n",
        "    {\"messages\": new_messages},\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8AcF-xT2ZeZ",
        "outputId": "b143aaf6-af76-454e-8cae-057aef717895"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Last 2 messages;\n",
            "[ToolMessage(content=\"LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows.  It's part of the LangChain ecosystem and draws inspiration from Pregel and Apache Beam.  You can find more information and tutorials online.\", id='94881f7a-d061-4c90-b646-96cc2b2ce538', tool_call_id='127bf7bb-986b-4aa3-8e08-1bb168ee165e'), AIMessage(content=\"LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows.  It's part of the LangChain ecosystem and draws inspiration from Pregel and Apache Beam.  You can find more information and tutorials online.\", additional_kwargs={}, response_metadata={}, id='32916c2a-39ba-4a7b-9ab5-f3f7f55736fb')]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"\\n\\nLast 2 messages;\")\n",
        "print (graph.get_state(config).values[\"messages\"][-2:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ny5K1o0ljRMp",
        "outputId": "45689a96-50c3-4d74-eb47-9ad2f62c5a3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "I'm learning LangGraph. search on it for me?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (127bf7bb-986b-4aa3-8e08-1bb168ee165e)\n",
            " Call ID: 127bf7bb-986b-4aa3-8e08-1bb168ee165e\n",
            "  Args:\n",
            "    query: LangGraph\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\n",
            "LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows.  It's part of the LangChain ecosystem and draws inspiration from Pregel and Apache Beam.  You can find more information and tutorials online.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows.  It's part of the LangChain ecosystem and draws inspiration from Pregel and Apache Beam.  You can find more information and tutorials online.\n"
          ]
        }
      ],
      "source": [
        "for m in graph.get_state(config).values[\"messages\"]:\n",
        "  m.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRAJd1HSj3Kn",
        "outputId": "b8927d82-b858-449f-f9a6-4bb20bdf937a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "snapshot = graph.get_state(config)\n",
        "snapshot.next     # ()   no any node because graph end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7Vh-KkamEui",
        "outputId": "5bb8cbf1-ef72-4d87-80b0-1404ffb39cb6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'configurable': {'thread_id': '4',\n",
              "  'checkpoint_ns': '',\n",
              "  'checkpoint_id': '1efe142b-48ca-61a8-8003-e78d5944a683'}}"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "graph.update_state(\n",
        "    config,\n",
        "    {\"messages\": [AIMessage(content=\"i am an exper in ai agents\")]},\n",
        "    as_node=\"chatbot\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwo81CM1mwGH",
        "outputId": "1bbec81b-d864-449a-e128-1b19c4f146e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "I'm learning LangGraph. search on it for me?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (127bf7bb-986b-4aa3-8e08-1bb168ee165e)\n",
            " Call ID: 127bf7bb-986b-4aa3-8e08-1bb168ee165e\n",
            "  Args:\n",
            "    query: LangGraph\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\n",
            "LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows.  It's part of the LangChain ecosystem and draws inspiration from Pregel and Apache Beam.  You can find more information and tutorials online.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows.  It's part of the LangChain ecosystem and draws inspiration from Pregel and Apache Beam.  You can find more information and tutorials online.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "i am an exper in ai agents\n"
          ]
        }
      ],
      "source": [
        "for m in graph.get_state(config).values[\"messages\"]:\n",
        "  m.pretty_print()      # swaped with two ai messages by last message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "HpsY2BbAnFfZ",
        "outputId": "f4cbb073-1b33-4c26-de34-22fa7ad7ab03"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lo-KXqmcpb8v",
        "outputId": "3e802e31-31e5-4e06-b24a-f7910f273331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ToolMessage(content=\"LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows.  It's part of the LangChain ecosystem and draws inspiration from Pregel and Apache Beam.  You can find more information and tutorials online.\", id='94881f7a-d061-4c90-b646-96cc2b2ce538', tool_call_id='127bf7bb-986b-4aa3-8e08-1bb168ee165e'), AIMessage(content=\"LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows.  It's part of the LangChain ecosystem and draws inspiration from Pregel and Apache Beam.  You can find more information and tutorials online.\", additional_kwargs={}, response_metadata={}, id='32916c2a-39ba-4a7b-9ab5-f3f7f55736fb'), AIMessage(content='i am an exper in ai agents', additional_kwargs={}, response_metadata={}, id='cfd6a5d1-b190-45aa-b793-cd19557546d3')]\n",
            "()\n"
          ]
        }
      ],
      "source": [
        "snapshot = graph.get_state(config)\n",
        "print(snapshot.values[\"messages\"][-3:])\n",
        "print(snapshot.next)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "WiIMFOHkqZlm"
      },
      "outputs": [],
      "source": [
        "\n",
        "from langchain_core.messages import HumanMessage\n",
        "user_goals = [HumanMessage(id=1, content=\"i want to learn ai\")]\n",
        "updated_goals = [HumanMessage(id=1, content=\"i want to learn ai with tools\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lzStSJ2rluP",
        "outputId": "4ca8bb7a-48b9-4893-8826-ac19bdc14117"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HumanMessage(content='i want to learn ai with tools', additional_kwargs={}, response_metadata={}, id='1')]\n"
          ]
        }
      ],
      "source": [
        "final_goals = add_messages(user_goals, updated_goals)\n",
        "print(final_goals)      # when id 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "_GEUf-zPsDaC"
      },
      "outputs": [],
      "source": [
        "# from langchain_core.messages import HumanMessage\n",
        "# user_goals = [HumanMessage(id=1, content=\"i want to learn ai\")]\n",
        "# updated_goals = [HumanMessage(id=2, content=\"i want to learn ai with tools\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "MJL5pSxXsFXk"
      },
      "outputs": [],
      "source": [
        "# final_goals = add_messages(user_goals, updated_goals)\n",
        "# print(final_goals)      # when id 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Pbplfx_qH8h",
        "outputId": "2ac994cf-97b5-4ee7-f5a3-4621aba1dcf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "I'm learning LangGraph. search it for me?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (7cff7dec-04bc-472f-a665-6b7ae13d8427)\n",
            " Call ID: 7cff7dec-04bc-472f-a665-6b7ae13d8427\n",
            "  Args:\n",
            "    query: LangGraph\n"
          ]
        }
      ],
      "source": [
        "user_input = \"I'm learning LangGraph. search it for me?\"\n",
        "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
        "\n",
        "events = graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
        "    config,\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "1jVod5nUX_FO"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import AIMessage\n",
        "\n",
        "snapshot = graph.get_state(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3T4iAn9GYO0u",
        "outputId": "ecd1e89d-4ca6-4466-f70b-621d78ae8aa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (7cff7dec-04bc-472f-a665-6b7ae13d8427)\n",
            " Call ID: 7cff7dec-04bc-472f-a665-6b7ae13d8427\n",
            "  Args:\n",
            "    query: LangGraph\n",
            "None\n",
            "message id run-464d854d-128e-45e5-a460-83a91ca506e0-0\n",
            "{'name': 'tavily_search_results_json', 'args': {'query': 'LangGraph'}, 'id': '7cff7dec-04bc-472f-a665-6b7ae13d8427', 'type': 'tool_call'}\n"
          ]
        }
      ],
      "source": [
        "existing_message = snapshot.values[\"messages\"][-1]\n",
        "print(\"original\")\n",
        "print(existing_message.pretty_print())\n",
        "print(\"message id\", existing_message.id)\n",
        "print(existing_message.tool_calls[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "Ls-o2cz4ZBu0"
      },
      "outputs": [],
      "source": [
        "new_tool_call = existing_message.tool_calls[0].copy()\n",
        "new_tool_call[\"args\"][\"query\"] = \"human-in-the-loop workflow\"\n",
        "new_message = AIMessage(\n",
        "    content=existing_message.content,\n",
        "    tool_calls=[new_tool_call],\n",
        "    id=existing_message.id,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Dv7sR50acpd",
        "outputId": "7640932d-2a1a-4fff-a20b-eb9e3570e2f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (7cff7dec-04bc-472f-a665-6b7ae13d8427)\n",
            " Call ID: 7cff7dec-04bc-472f-a665-6b7ae13d8427\n",
            "  Args:\n",
            "    query: human-in-the-loop workflow\n"
          ]
        }
      ],
      "source": [
        "new_message.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tW4A-UUWZ7o6",
        "outputId": "a82a604b-495f-4935-b94b-87b39fcc8dd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updated\n",
            "{'name': 'tavily_search_results_json', 'args': {'query': 'human-in-the-loop workflow'}, 'id': '7cff7dec-04bc-472f-a665-6b7ae13d8427', 'type': 'tool_call'}\n",
            "message id run-464d854d-128e-45e5-a460-83a91ca506e0-0\n"
          ]
        }
      ],
      "source": [
        "print(\"updated\")\n",
        "print(new_message.tool_calls[0])\n",
        "print(\"message id\", new_message.id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U37eyTHdcTg7",
        "outputId": "a73a7439-52c6-45d9-a386-66152d33ac32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Tool calls\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'tavily_search_results_json',\n",
              "  'args': {'query': 'human-in-the-loop workflow'},\n",
              "  'id': '7cff7dec-04bc-472f-a665-6b7ae13d8427',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "graph.update_state(config, {\"messages\": [new_message]})\n",
        "print(\"\\n\\nTool calls\")\n",
        "graph.get_state(config).values[\"messages\"][-1].tool_calls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FzuTK4JeuiA",
        "outputId": "e8eceb9a-4d37-45a6-dede-02437e10d582"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "I'm learning LangGraph. search it for me?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (7cff7dec-04bc-472f-a665-6b7ae13d8427)\n",
            " Call ID: 7cff7dec-04bc-472f-a665-6b7ae13d8427\n",
            "  Args:\n",
            "    query: human-in-the-loop workflow\n"
          ]
        }
      ],
      "source": [
        "for m in graph.get_state(config).values[\"messages\"]:\n",
        "  m.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eB8fLrKge9ZA",
        "outputId": "da5eab14-57ef-4383-8a0d-cb803cc597a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (7cff7dec-04bc-472f-a665-6b7ae13d8427)\n",
            " Call ID: 7cff7dec-04bc-472f-a665-6b7ae13d8427\n",
            "  Args:\n",
            "    query: human-in-the-loop workflow\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search_results_json\n",
            "\n",
            "[{\"url\": \"https://camunda.com/blog/2024/06/what-is-human-in-the-loop-automation/\", \"content\": \"Human in the Loop (HITL) automation is a hybrid approach where automated systems and human judgment are integrated into a single workflow. Unlike full automation, which operates without any human input, HITL ensures that humans can intervene at specific stages to provide oversight, make decisions, and guide the automation process.\"}, {\"url\": \"https://nordicapis.com/what-is-human-in-the-loop-workflow-automation/\", \"content\": \"HITL: Human Automation Hybrid Ultimately, Human-in-the-Loop is a useful paradigm when implemented within the appropriate circumstances. Allowing humans to add value to an automated chain is an excellent option in most automated workflows and can create unparalleled effectiveness and increased accountability. What do you think about HITL?\"}]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Based on the search results, Human-in-the-Loop (HITL) automation is a hybrid approach combining automated systems and human judgment.  Humans intervene at certain points to oversee, decide, and guide the automation process.  This contrasts with fully automated systems that operate without human input.  The effectiveness of HITL depends on the specific circumstances and can improve automation workflows by increasing both effectiveness and accountability.\n"
          ]
        }
      ],
      "source": [
        "events = graph.stream(None, config, stream_mode=\"values\")\n",
        "for event in events:\n",
        "  if \"messages\" in event:\n",
        "    event[\"messages\"][-1].pretty_print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "hfJWowqqenOT"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import StateGraph, START\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "    name: str\n",
        "    ask_human: bool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "AUBTOgI7fof8"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "class RequestAssistance(BaseModel):\n",
        "  \"\"\"esclate the converstion to an expert\"\"\"\n",
        "  request: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtRH7KF0gvSs",
        "outputId": "d207d217-e633-4f7d-c8fc-b641c970ed91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "request='i need help'\n",
            "i need help\n"
          ]
        }
      ],
      "source": [
        "abc = RequestAssistance(request=\"i need help\")\n",
        "print(abc)\n",
        "print(abc.request)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "7_AvVf01jBvZ"
      },
      "outputs": [],
      "source": [
        "tool = TavilySearchResults(max_results=2)\n",
        "tools = [tool]\n",
        "llm_with_tools = llm.bind_tools(tools + [RequestAssistance])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQXwv11pjRZ4",
        "outputId": "0b930768-565f-4d38-e70a-74052c5737ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RunnableBinding(bound=ChatGoogleGenerativeAI(model='models/gemini-1.5-flash', google_api_key=SecretStr('**********'), max_retries=2, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x79ee112e99d0>, default_metadata=()), kwargs={'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'RequestAssistance', 'description': 'esclate the converstion to an expert', 'parameters': {'properties': {'request': {'type': 'string'}}, 'required': ['request'], 'type': 'object'}}}]}, config={}, config_factories=[])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "llm_with_tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9fq6GNPjh7_",
        "outputId": "2038ec05-6fc1-4f61-a357-6aeada2a2f0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  RequestAssistance (52490c6d-60d5-4656-b480-ea112d783f0e)\n",
            " Call ID: 52490c6d-60d5-4656-b480-ea112d783f0e\n",
            "  Args:\n",
            "    request: connect me with a langraph expert for paid project\n"
          ]
        }
      ],
      "source": [
        "response = llm_with_tools.invoke(\"connect me with a langraph expert for paid project\")\n",
        "response.pretty_print()       # connected with human"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPXbDOdekj3q",
        "outputId": "1e6d6938-f193-4ea1-cd5e-0d35f0a53c50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (4aa1f6d7-6a33-4bb8-8bc9-d340040cb8dc)\n",
            " Call ID: 4aa1f6d7-6a33-4bb8-8bc9-d340040cb8dc\n",
            "  Args:\n",
            "    query: langraph expert for paid project\n"
          ]
        }
      ],
      "source": [
        "response = llm_with_tools.invoke(\"search about langraph expert for paid project\")\n",
        "response.pretty_print()       # searching using tavily"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RKKmIjfk1Fk",
        "outputId": "744adc50-4dbf-47ce-e012-3967d1969f6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello! How can I help you today?\n"
          ]
        }
      ],
      "source": [
        "response = llm_with_tools.invoke(\"hello\")\n",
        "response.pretty_print()       # replying by itself"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "qmVr9fnsh8Cb"
      },
      "outputs": [],
      "source": [
        "def chatbot(state: State):\n",
        "    message = llm_with_tools.invoke(state[\"messages\"])\n",
        "    ask_human = False\n",
        "    if (\n",
        "        response.tool_calls\n",
        "        and response.tool_calls[0][\"name\"] == RequestAssistance.__name__\n",
        "    ):\n",
        "        ask_human = True\n",
        "    return {\"messages\": [message], \"ask_human\": ask_human}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAjw6NjnmF8Q",
        "outputId": "a9bb4b8b-1859-44e8-b7cb-2bfb4bb7734d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x79edd80cbcd0>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "graph_builder = StateGraph(State)\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "graph_builder.add_node(\"tools\", ToolNode(tools=[tool]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiRVZyHpi5it",
        "outputId": "5ad064f6-dc42-4b89-a64f-6e827c6fe775"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x79edd80cbcd0>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "from langchain_core.messages import AIMessage, ToolMessage\n",
        "\n",
        "def create_response(response: str, ai_message: AIMessage):\n",
        "  return ToolMessage(\n",
        "      content=response,\n",
        "      tool_call_id=ai_message.tool_calls[0][\"id\"],\n",
        "  )\n",
        "\n",
        "\n",
        "def human_node(state: State):\n",
        "  new_messages = []\n",
        "  if not isinstance(state[\"messages\"][-1], ToolMessage):\n",
        "    new_messages.append(\n",
        "      create_response(\"no response from human.\", state[\"messages\"][-1])\n",
        "    )\n",
        "  return{\n",
        "        \"messages\": new_messages,\n",
        "        \"ask_human\": False,\n",
        "    }\n",
        "\n",
        "graph_builder.add_node(\"human\", human_node)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlkz8IAunaQ2",
        "outputId": "dbb8f13c-7d71-4406-acbb-51286ed9571f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x79edd80cbcd0>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "def select_next_node(state: State):\n",
        "  if state[\"ask_human\"]:\n",
        "     return \"human\"\n",
        "  return tools_condition(state)\n",
        "\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    select_next_node,\n",
        "    {\"human\": \"human\", \"tools\": \"tools\", END: END}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "fO03F6wqqbXG"
      },
      "outputs": [],
      "source": [
        "\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(\"human\", \"chatbot\")\n",
        "memory = MemorySaver()\n",
        "graph = graph_builder.compile(\n",
        "    checkpointer=memory,\n",
        "    interrupt_before=[\"human\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "7zXivEg-ySl5",
        "outputId": "88517a41-164b-4a54-ffbe-828ec7fce910"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaMAAAEjCAIAAAAQR/l7AAAAAXNSR0IArs4c6QAAIABJREFUeJzt3XdYU9f/B/CTHUjYU1BkyXAgKFgHbnHhFhT3Xjhq0bqqVVtr1brqtgpo3YKzLhx1o1ixUhcKsmTJSghJyM7vj8uX8qOIqElOcvN5PX36hOTm3ncEPpx7z7nnUNRqNQIAAFKj4g4AAABaB5UOAEB+UOkAAOQHlQ4AQH5Q6QAA5AeVDgBAfnTcAcAneJ8jEVcoKyuUcplKWqnCHadBWGwqnUkxNaObmFEdm5rgjgOMFAXG0+m/jGfCjGeizOciFx9TuVRlYkazdmDKpYbxjWOyqWXvZeIKBZ1ByX4ldmvJcW/J9fTn4s4FjAtUOr2W/lR4/48SJw+Txp4mbi05bFMa7kRfRCZRZT4X5bwW5aZVdhxg6x1ohjsRMBZQ6fRUpUh57ch7BpPSaaCtuQ0DdxwNE/IViRdKKnjyPuMacS3hEgrQOqh0+ig3TXzlQOGQ2c62TizcWbSo7L303O787iPsXZtzcGcBJAeVTu+U5EvvnikZOtsZdxAd+eO3/KDe1o6ubNxBAJlBpdMv6SnCf+7yh81pjDuITp3fm98sgOvbzhx3EEBaMJ5Oj/CKZA8vlhpbmUMIDZrh9M+d8qJcCe4ggLSg0umRWyeLRi92wZ0Cj5ELm9w7V6KUG8YgQWBwoNLpi8QLJS4+HCqNgjsINp5+3HvnS3GnAOQElU4vSCuVz+8L2vaywh0EJ7/OlhnPhEK+AncQQEJQ6fTC3zf5XcNscafAr8swu5TbfNwpAAlBpdMLzxPLXbx1NKZMKBSmpqbienv9mvqY/nO/XEs7B8YMKh1+BVmVlrZME66O7vSKiIg4d+4crrfXj86kOrmxc16LtbR/YLSg0uGX+6bSO1B3d7zLZLLPeyMx9PKz395AXm25eWlQ6YCGQaXDrzhXamqulXs/7927N3LkyE6dOoWHh584cQIhNGDAgLKysri4uMDAwAEDBhCbnT9/fuzYse3bt+/Ro8d3333H4/GI59evX9+7d+87d+4MHTo0MDDwr7/+qvPtmsWxYBS9k2pjz8CYwc3V+IkrlKZmmj91FYvFixcvdnd3X758eXp6enFxMUJow4YNc+bMadu27ZgxY5hMJrHls2fPXF1d+/fvX1ZWdvz4cZFItHXrVuIloVC4a9euJUuWVFZWBgUF1fl2zeKY00QCpTb2DIwZVDr8xAKFNtp0ZWVlUqm0R48e/fr1q36yefPmdDrd1tbW39+/+slly5ZRKFXj+Oh0ekxMjFQqZbFYxLnq8uXLW7ZsWc/bNYtjThcJYKAJ0DCodPgxWFQ6XfMDhp2dnf38/KKjo01MTIYNG1ZPE0wulx8/fvzSpUuFhYVsNlulUvF4PEdHR4QQm82uLnO6QaVTWGy4qAI0DH6k8KPRKcJyzbdiKBTKtm3bBgwYsHXr1mHDhj158qTOzdRq9fz582NiYgYNGrRjx47+/fsjhFSqqruyTE1NNR6sfqJyhTHfKAK0BCodfqbmNLF2rkxxudwlS5acOnWKy+VGRUWJxVV9mjUnsHny5MmjR4+WLFkyevToli1benp6fnS3Wp3/RixQcrTTPwOMGVQ6/OycWdJKrVQ6qVRKnMZGREQIhcL8/HyEkImJSUlJSfU2fD4fIeTj41Pzy+o23X/VervGVYoU9i5knn8UYAF/PPFr5Gby9y2eT5CGZ2eTy+XDhw8PCQnx8PCIi4vjcrmNGzdGCAUEBFy5cuXAgQPm5uZ+fn6tWrViMpk7duwYOnRoWlpabGwsQig9PZ3Y+L9qvb0hbcBPkvZE2KwNrC8BNAzadPi5+JjmpVcqFRo+JSTGhVy+fHndunUMBmPr1q1sNhshNG/evMDAwP3798fGxr57987e3v6nn35KTU1dtGhRUlLS3r17g4ODjx8//qHd1nq7ZjMjhDKei9xbwmTrQMNgzmG9cPdMceNmJm4tjX1twHdp4vS/hd1H2OMOAsgGzl71QsuOFhdjCuqpdPv27Tty5Mh/n/f19X316lWdb4mNjXVzc9NozNqEQuGH7pSwsrKqvteipm3btvn5+X1oh4l/lHYPs9NoRgAQtOn0yPWj7509TT60loJAIBAKhf99nkL54HfQ3t6eTtfuXzKVSlVYWFjnS3K5nMGoY/FGW1vbD43sS08Rpj2p6DepkaZjAgCVTm+IBYobJ4oGTnPCHQSby7EFHQbaWNpq5SYzYOSgR0JfmJrTW3Wy+OO3fNxB8LhysNDTnwtlDmgJVDo94tqc4+Ru8ufxItxBdO3O6WILW0azABhcArQFzl71TtrfFe/eVPYYaSz9j3fPFNs4MZt/ZYE7CCAzaNPpnWYBZrZOzNM7cpVK8v8ROr8339ScDmUOaBu06fRUXnrlrbiiZm3M2vWxxp1FK5Jv8J7dLe8+0q6pL4wTBloHlU5/qVXqRwllf9/kB4ZYufiY2jdh406kAcV50pxUcfJ1XsuO5u1DbahUmLYE6AJUOn0nl6n+uctPfyoSCRQ+QWYUROFY0MysGYbyfaNRKeVlMlG5Uq1Wv0kWsk2pHq25fp0tWCY6WiEIAKh0hkRUrshLrxTw5KJyJYWCKngantKuoKBApVI5Oztrdrdm1gy1Us2xoJlZ053cTcys6hhODIC2QaUDVaKjo6VSaWRkJO4gAGge9L0CAMgPKh0AgPxgLhNQhcPhaGlhQwCwg0oHqohEImI2dgDIByodqMJgMOpZPgIAgwbX6UAVuVwul8txpwBAK6BNB6qw2WwKBe5YAOQElQ5UkUgkcJ0OkBVUOlCFy+WyWLDQKiAnqHSgilAohDYdICvokQAAkB+06UAVGDYMSAzadKCKTCaDs1dAVtCmA1WYTCZMbAPICtp0oIpMJpPJZLhTAKAVUOkAAOQHZ6+giomJCZ0OPw+AnOAnG1SprKyEHglAVnD2CgAgP2jTgSowEycgMah0oArMxAlIDM5eAQDkB206UAXOXgGJQaUDVeDsFZAYnL0CAMgP2nSgCpy9AhKDSgeqwNkrIDE4ewUAkB+06UAVWO8VkBi06UAVWO8VkBi06UAVU1NTmMsEkBX8ZIMqYrEYeiQAWcHZKwCA/KBNB6owmUwKhYI7BQBaAZUOVIG1wQCJQaUDVbhcLovFwp0CAK2ASgeqCIVCaNMBsoJKB6rAfa+AxKDSgSpw3ysgMah0oAqbzabRaLhTAKAVFLVajTsDwGnAgAFUKlWlUonFYpVKZW5urlKp1Gr1xYsXcUcDQGOgTWfsPDw87t+/X/2lUChECLVr1w5rKAA0DO6RMHYTJ060sbGp+YyFhcWYMWPwJQJA86DSGbuAgABfX9/qixhqtdrDw6NTp064cwGgSVDpABo/fnx1s87S0nLSpEm4EwGgYVDpAGrTpk2rVq2Ix56enh06dMCdCAANg0oHEEJo3Lhx1tbW5ubmEyZMwJ0FAM2Dvlc9xS+W8YvlOpvt3JzerK1v/8rKSkfz1hnPRbo5KJWKLGwZVvZwYwbQOhhPp3eyXor+vsmv4CmaeJlW8BS442gRx4Ke/1bMMaf5dbH0bM3FHQeQGbTp9Ev2a/Hja7xeY51odGO5sKBSqW8cyadQkIcfFDugLcby62QQCjIrH/xR2mdiY+MpcwghKpUSMs7571vl2ali3FkAaRnRb5T+S77B6zjYHncKPDoNtn96i487BSAtqHR6JPuV2MLWSC/Pcy0ZeelipQKuGgOtgEqnL4R8hV1jNpVqvCs5OLqa8EtgwVmgFVDp9AWFgkR8o/49FwsUVFiyB2gHVDoAAPlBpQMAkB9UOgAA+UGlAwCQH1Q6AAD5QaUDAJAfVDoAAPlBpQMAkB9UOgAA+UGlAwCQH1Q6AAD5QaUjoeXfL5gxc+ynvksoFL5JS63+Mi39dfeegQ8e3P3U/RQWFhQU5n/quwDQKqh0oMrU6RGXL5/7wp3k5eeOHjvo9euXGgoFgGZApQNVZDLZl+9EqVDAyiRAD8E6Eobt/fvC/TE7//rrgVgs8vDwGhE+tnu3EOKlAwd/++PCKaVS2a1rr8hZUUwmEyF0+cr5s2dPZmSmm5iYtgvqMGf2QktLK4RQxOgBPF7Z2XNxZ8/FOTg4Hj96gdjJn7eu7vnt18LCfE9P7xnT5vn5BRDPl5aW7N6zJenRfYVC0aql/8wZ893dPQsK8ydMCkMIrf5hyWqE+vQZsGTRKnz/NgD8CyqdASstLZk9d6JSqYwYOd7K0vqfZ3+XlBQRL71JS2Wx2TOmzUtLfx1/6qi1te34cVMRQi9fPnNxcQ0J6c/jlZ0+c1wkFv3801aE0KqVGxYtnuPfum142BgG8995j7My34YNHy0UVpw6fWzBt7N+3bKvefNWEokkauFMgaB8+rR5bBb72ImDUQtnHvr9jI217XfL1vy0dvmkiTMD/AOtrKyx/dMA8P9BpTNgvx/ax+fzYvafcHFxRQj16TOg+iUnp8ZbNu2l0Wi9e4fm5GTeun2NqHRR3yyj/G+2SzqdfvhIjFQqZbFYPt7N6XS6jY1tq1b+NQ8xedKsDh06I4RCevWfODlsf/TOzZv2XLt+KScna9PG3W0CghBCrVoFjB476PTp4xPGT/Nq5oMQcnFxrbUfAPCCSmfAkh7dbxMQRJS5WrgcLo1GIx67unq8fPWMeCyXy0+fOX7t+qWiokIWi61Sqfh8noOD40ePZWtrF9yp+/UblxUKRUpKMpfDJcocQsjRsZGLi+vrN9ALAfQX9EgYMB6vzM7O4aOb0Wg0hUKBEFKr1cu+m3/kaEy/voPWr9sR0qs/QkilVjXwcHZ29kqlUiKRCEVCC0urmi+Zm1uUlhR/7ucAQOugTWfAuFyzMl5pw7dPSXmS/OTRd8vW9OrZFyGUl5tTa4P6u015vDI2m83hcOxs7V++fFbzpbKyUgf7jzcMAcAF2nQGrE1A0JMnj2oO0yXabh9SLuAjhIhLadVfqlRVbToTtklpacmH3iuRSB4m3fP3D6RQKC1a+FVUCF69ek689PZtWl7eO+LCHIvFRghB+w7oG2jTGbBxY6cmPrgzZ+6kYUMjrK1tHj9+aGJiunDB8g9t39y3FZPJ3Ld/R2jo0IyMtKPHYhFCmRnpzk6NiY6FG39eOXrsgJmZeYvmfsRb9sfsLOOVisWiKwl/CATlEyfMQAj16tnvyNHYVT8sHjd2KpVKPXRov6Wl1eBB4Qghe3sHp0bOJ+MPs01MBILyEeFjqy8XAoARtOkMmIuL6/ZfYzw9vA4fid69e0vh+wJ//8B6trezs1/+3U9p6amrVi9KTk7avGlv+/bBp88cJ16dMX1egH/gocP7jx6Nzct/R+w/uFO3Q4f3R8fs4nLNNm/c4+3lS3Ta/rJ+p7dX8917tmzf8YuLi+uvW/YRY0ooFMry5WtNTTk7dm68kvCHVCrV1T8GAPWhwIh2PSEqV5zc/C4syg13EGzO7cwOneJk5cDAHQSQELTpAADkB5UOAEB+UOkAAOQHlQ4AQH5Q6YC+UCqUO3fufPHiBe4ggISg0gF9QaXRfHx83r59ixA6d+7cunXrsrKycIcCJAEjh4G+oFBQz549iVEmXbt2lclk2dnZrq6u0dHRfD5//PjxdnZ2uDMCQwWVDugjS0vL8PBw4vHAgQOvX7+em5trZ2e3ceNGJpM5efJkLpeLOyMwJHD2CvSdvb396NGjAwICEELh4eEWFhYlJSUIoWXLlu3atUsul+MOCAwAVDpgSJo2bTphwgRXV1eE0IQJE1gsVmVlJUIoMjIyJiYGdzqgv+DsFeiRO3fuSFQllZWV5eXlxcXFpaWllZWVUqmUy+Xu27ev1sbe3t7e3t7E4+nTpycnJyOESktLV65cGRISMnjwYByfAOgpqHRAX8hk8tjYWL44VyQSEXNJqdVqYi54oorVw9/f39/fHyFkY2MzZswYogP38uXLCQkJ06dPb968ua4+BNBTUOmAvmAyGYGBgX8kpFUXOOL/tra2n7SfDh06dOjQASEUEhLC5XJFIhFCaMuWLQUFBZGRkcSZLzA2UOn0BYVCsXJg4U6Bk4Utc97w2SWCrPv371dPsaNWq3fs2PF5O6TT6Z07dyYez5o16/79++Xl5Qih6OjorKysKVOmQNUzHrRVq2BFTr3AF5Q+uSZ09zNnsIyxm0gmVSVdKu40yLZv376JiYlFRVXLObJYrMePH1+6dInBYHh5eX32/ul0uru7u6OjI0LIy8tLpVJRqVQnJ6fly5c/fPiwTZs2zBprPwLygUqnF5KTk+fMmdMnZBBFzTDOll3+W5EJh+banIMQGjJkSEJCAtH+cnZ2jo+Pd3d3v3bt2vLly8vLy52cnCwtLb/kWEwms1mzZk5OTgihli1bikQiJycnDocTGRn59u3bwMBAKtUY/9iQG8zEidP79+/Pnz8/bdq0rKws4kzq9zXZwUPt7Rqb4I6mU+UlsqsH8yb/8O8spEVFRTNnzszJyXn8+HH1kxKJ5NSpU6dOnbKzswsLCwsJCdFsjDdv3jx48CAiIoLFYkVFRfn7+48dOxaqHjlApcNDLpczGIxBgwZFRUV169at+nmlUn1sfY53oAXHimHtyEKk/uZQqOqyQpmQL3+RyB+7xIXOrF1Thg8ffurUqf++8fHjx/Hx8SkpKaGhoWFhYcQ5qWb99ddfiYmJM2bMkEqlGzdu7NOnT3BwsMaPAnQGKp2uCQSCzZs3R0RE+Pj4fGibv2/xct9UqtWUskJNrsMgkUjYbPaHXiXWFaPTdddJZeXApFBQ42YmbXpYNWDz2oRCYVxcXHx8vKenZ3h4uJYqkVqtvnz5clZWVmRk5PPnz2/cuBEaGurp6amNYwHtgUqnOyUlJba2tvv27XN0dBw4cKCOj75mzZqrV6926dJlzZo1dW4QHR0tlUojIyN1HOzL3bt3Ly4uLj09fdy4cUOGDKmnmn8hsVgcHx8vk8mmTp2alJSUk5MTEhLyhRcNgW5ApdMRYua1Xbt2YTn6nDlznj59KpFIunTpsnnz5jq3SUtLUyqV9bQ09VxhYeGFCxdiY2P79esXERGh7WZXYWHhgQMHrKysZsyYkZycrFAovvrqK60eEXwJqHTaVVBQkJeXFxgYeOfOnS5duug+gFAonD17NjG9pUqlCgwM/O2333QfQ5fOnDlz/PhxS0vLUaNG1bwGqj2pqanbtm3r2rXryJEjHz9+7Orq+qmjnYG2QaXTort3765fv37nzp1NmzbFEiArK2vRokUZGRnVz7i4uJw+fbrOje/fv69SqaqH2hq6x48fHzt2TCKRdO/ePSwsTAdHJG7tOHPmzJ49ezZt2tSyZcv09HS4oqcnoAdd8/h8/q1btxBCDg4OFy5cwFXmEEJz586tWeYQQlKpVKlU1rnxmzdvUlJSdBVN6wIDAzdt2rRixYq0tLTOnTtHR0cTXS7aQ9y7NnTo0ISEBDc3N4TQ77//3qtXL4FAoNXjgoaASqdhhYWFw4cPJ05evmRMv6YQt8pXo9PpfD6/zi2HDh06atQoXeXSEUdHx6VLlyYkJEil0k6dOm3evLm0tFQHx+VwOAihH374IS4ujrj7omPHjosXL/7vdwToBpy9asyePXsiIiJUKpW1tTXuLP9P3759y8rKiF8wJyen7du3Y2xm4nXkyJEbN254enpGRkbqvs/07t27nTt3LiwsXLFiRVhYWJ8+fXQcwJhBm04zFi1aRKPRLC0t9a3MIYRatWq1bt26x48f29raCoXCD5W5lJSUOofpksmYMWNiYmK8vb2HDx++adMmYhZPnSGugTo6Os6aNYuYNvnp06cxMTHEY6BV0Kb7IpcvXy4oKJg8ebJCodDlmNuGKysrmzlz5smTJz+6ZVJS0sGDB3GNg9G9o0eP7tq1a+TIkZGRkTQaDUsGoVB48OBBCoUSGRn55MkTc3Nz6MHQEmjTfb7nz5/fv38/IiJCx7cWfJLTp0+HhoY2ZEt/f/9FixZpP5G+GD169L1798zMzDp06HD8+HEsGbhc7uzZs4nR2hQK5bvvvrt69SpxQzSWPCQGbbpPVlJSsn379tWrV4vFYlNTU9xxPiI4OPjatWsmJsY1ZcCnOnLkyKFDh5YtW4ZlzGNNQqGQy+X+/PPPKSkpu3bt0sOLIQYKZm36ZN98882wYcNcXFwYDAbuLB9x5swZW1vbho+eXbhwYcuWLc3MzLScS+/4+fn16dNn3759ly5datOmDcYlFomO2s6dO7du3ZrNZpuami5YsKC8vLxFixa4IpEDnL021MWLF8+dO4cQ2rt3b6dOnXDHaZDY2NixY8c2fHtTU9O///5bm4n0l52d3ZYtW0aOHDlp0iR9uFjZrFkzYqzS1KlTMzMzZTKZUChMSEjAnctQQaVrkOTk5KSkpAEDBuAO8gkSEhJatmzp7Ozc8LfMmzevdevW2gyl7zp16nTp0iUWizV58mQ9Kfq+vr6LFy9mMplsNvv27dsTJkwgRqfjzmVo1KBeO3fuVKvVPB4Pd5BP9vXXX2dkZOBOYajKy8unTJmyY8cO3EFqUygUarU6KSlp8ODBT548wR3HYECbrj5Lly4lLgkb3Mw8V65c4XA4xD1Jn2TEiBGFhYXaCWVIzM3N9+/fb2JiMmbMmLKyMtxx/kUMiGnXrt327duJ+9sOHjx4+/Zt3Ln0HfRI1O306dO+vr7t27dv06YN7iyfY9u2bVFRUZ/Rt1BQUMDj8WCBVEJAQECLFi0mT55sbW2tD/f21WRhYUFcmmCz2UePHrW3t2/UqBGfz9fe9HwGDUaZ1KZUKnv27Llp06a2bdvizvKZTpw4kZ2dbVSD47Rt5cqVVlZW8+fPxx3kg4j5+qdMmWJjY7Nu3TpY/qIWqHT/T3p6epMmTWQymUGPtAgMDKy50MynksvldDqdmJkDVLt582ZcXJw+dMvW78aNG127di0pKXn48OGQIUNwx9EXUPirKBSKiIgINpvNYrEMuszt27fv+++//5I9nDhxYuvWrZpLRBLdu3efMGHCmDFjcAf5iJ49e9LpdBsbm2fPnq1cuZKYqgt3KPygTYeIH4UXL16YmZk1a9YMd5Yvkpqa+uOPPx45cuRLdqJQKKKiorZt26a5XOSRmpr67bff/vHHH7iDNAhxSrt161aRSLRgwQJjvoQHlQ4dOXIkNDTU4HpX6zRq1KjVq1fr27VzksnPz4+IiLhz5w7uIJ/g9OnTHh4erVu3zsnJcXFxwR0HA2M/e/3nn3/ev39PjjJ39OjRbt26aaTMiUSi/fv3ayIUCTk5OZ06dWrixIm4g3yCYcOGEWPCt2zZQkwIamyMvdJZWFhERUXhTqEB2dnZ8fHxM2bM0MjeOBxOcXFxfHy8RvZGPnZ2dqNHj166dCnuIJ9sy5Yt/fr1I9YYKSgowB1Hd4x3PN3u3bvlcnmrVq1wB9GMGTNmbNy4UYON0w4dOtBoNDs7O03tkGQ8PDwSExP5fL7BrRvp6upKPJg0aZKrq2uTJk1wJ9IFI71Od+HChUaNGhnuiLlaNm3a1KhRo9GjR+MOYnRCQ0Ojo6MdHR1xB/lMr1698vX1vXz5MtHQIzEjPXsdMGAAacrcrVu38vPztVTmhg8frlf3QumbvXv3GvRlL19fX+KyLDFxAIkZXaV7/fr1Fw430ysVFRXbtm3btGmTlvb//fffN2RmdqPVuHFjb29vQ19/IywsbP369cQYGtxZtAb3FAO6NmvWLLFYjDuFxgwdOjQrKwt3CqOWk5MzePBg3Ck0o7CwsF27dgUFBbiDaJ7Rtel27dpFmqnGly5dOnPmTB0sabhhwwZtH8JwNWnSpF27do8ePcIdRAMcHBzu37+fl5dHvkVpjajSicViMk1uc/z4cQ8Pj969e+vgWB07dvz66691cCAD1bRp03v37uFOoRl0Or1t27YUCqVXr148Hg93HI0xokq3bdu2oqIi3Ck04/bt248ePZo6dapuDhccHLxp0yalUqmbwxmc4ODg9PR03Ck0iUKhxMXFXb9+HXcQjTGWSqdUKu3s7MLDw3EH0YD09PRdu3Zt3rxZlwel0+mJiYk6XgraUDRt2jQ5OZmYF5M0rKysiN8X/Z++pSGMpdLRaLQpU6bgTqEBUql03bp1J06c0P2hvby8hg8frvvjGoTGjRvn5ubiTqEVzs7Oe/fuxZ3iSxlLpYuJiUlMTMSdQgP69u2r49ZcNQcHh9jY2FevXmE5up5r3bp1cXEx7hRaMXjw4B49euBO8aWMpdJdv37dxsYGd4ovNWLEiP3795ubm+MK4ODg0KxZM7hg91+FhYXk66+sRsxmNn36dNxBPp+xVLqJEyd6e3vjTvFF1q5du2jRIg8PD7wx6HT6tGnTUlJS8MbQN8TKSuT2yy+/7N69G3eKz2QslU43ozG0Z8mSJUFBQYGBgbiDoOpLASS7AP+FcnJyuFwu7hTaZWFhMXnyZNwpPpNRVDqhUGjQUzOtXbs2KCgoJCQEd5B/zZo1i06n406hR4qKiuzt7XGn0DoWi5Wenm6IN8kaRaVjMpkPHjzAneIzbdu2zdnZWQ87PRMTE5ctW4Y7hV5QKpXOzs5GMsOVp6fnsmXL4uLicAf5NEbxZ5nJZP74448qlcrgloaLjo6m0+n6+Se0Y8eONBrtzz//JEHH3Bd68eIFibsj/svb29vgrnoby/x0YWFhMplMKpWWl5c3bdoUy3i0T3Xu3Lni4mKd3QgBPtvp06cLCgpmz56NO4hOrV69etiwYYYyl62BtXE+Vdu2bdu2bRsYGJiVlZWfn19aWiqXy/v06YM718fFx8e/fPnSIMrcihUrnj59ijsFTnfu3PHz88OdQteWL19+4MAB3CkaiuSVLjg4uNYKzXZ2dh07dsSXqEGuXLlSVFRkKMsU/Pjjjzdv3iwtLcUdBJt79+517twZdwpdo9Fo2psYUeNIXulWr15dc+ZrtVrt4OCg5xP/nz9/PikpKTIyEneQT/DNN9+QYGD250lMTNTD/iKdOXXqVHbdvwMlAAAcbUlEQVR2Nu4UH0fySmdpaTlnzhxTU9PqZ7p164Y10UdcvXr1zZs3xNLrhkUoFI4aNQp3Cgzi4+P1/yxBe9q0abNgwQLcKT6O5JWOuFG0U6dORMeLnp+6Xr58+c6dOwsXLsQd5HNwudytW7fiuicXl4qKCoFA0LVrV9xBsHFzc9uxYwefz8cd5COMou9VLpeHh4fn5ub6+voeOnQId5y6Xb169ebNmz///DPuIOAT7N27l0KhGPQNoV9OrVYLBAILCwvcQerToPF0CrmqUmjQw4Uo8yIXb9iwoUeX0AqePt7DdP/+/Tt3kpYt/VFT8SgUxLXEM1gyKSnp4cOHRjJH8eHDhxMSEnCnwIxCoaxfv75r1676PKrhI226V48E/9wtLyuUmXBpOkxlXNQqlUqtptE0+S9s68TKz6z0CjDrOtyWQqU04B2a9OjRo3fv3pH+On18fHxubu78+fNxB8EvPT39yJEj+nx9ub5K9+hqWUm+3L+rtZk1Q7epgAZIK5Wl+ZJrhwqmr3Nnssh/QVb3OnfunJCQULO/C+itD1a6pCtlglJF+wHkv2mZ3OQy1cmNmTPXY5jr6fDhw0wmc8SIEbo/tA6cOHFCKpWOHz8edxB98e7dO7lc7u7ujjtI3er+U88rkpXkSaHMkQCDSe040O7BhRLdH3rs2LFOTk6kvH1CJBLt3LkTylxNcrl88eLFuFN8UN2VriRPqlbr+uIO0BJzG2Z2Kp6VboKDg729vaVSKZaja09sbOyKFStwp9Av7u7u/fv3FwgEuIPUre5KJyxX2jVh6zwM0AorRzaDie06nYmJydq1ay9cuIArgMY9efIkJSVFr6YL1BOTJk3COPV//er+BZBLVXKJQQ8rAf9Sq9TvcyQYA6xevZqYwRFjBg06fPjwqlWrcKfQR2lpaUlJSbhT1A265IAuhISEeHp64k6hAbt27WrRooWzszPuIPpIIpHo7UITUOmA7kRFRT18+BB3is+XmZmZnZ1NjoWDtcHX17d79+64U9QNKh3Qnc2bN4vF4sLCQtxBPtP8+fPnzp2LO4X+0tv5saHSAV3r0aMHn8/X2x66esTExEycOLFx48a4g+i1e/fu6efd/lDpgK75+Phs2rTJsMbZPXjw4MmTJ0OHDsUdRN8dO3YsNTUVd4o6GMWKOUDfrF69WiKRGNAaRhs2bDhz5gzuFAbAz89Ps3dwa4ph/JwB8mGz2adOnap5za5///5YE33QqlWrYJxwA82YMSMoKAh3ijpApQPYhIeHr1u37s2bN8T1O/1cOiMmJsbOzq5Nmza4gxiGzMxM/exxgkoHcNq6dauXl1e/fv2IPooXL17weDzcof71/Pnz27dvG9vyhl8iLi7u9u3buFPUAa7TAcz69OlTva4Yn89/8uRJz549cYeqMmvWLJho85N069aNy+XiTlEHaNMBnLp3715z+USxWKw/LYKoqKg1a9bA9HOfpF27ds2bN8edog4GXOmWf79gxsyxuFOAzxcWFiYSiWo9+ezZM6FQiCnRv06cOOHo6GjMS+F8nlu3biUnJ+NOUQcDrnTA0MXHxy9atCgoKMje3p5CqZoUVigUPn78GG+wjIwMIhveGIYoOTn59evXuFPUAa7TAZzCwsLCwsJyc3Nv3rx5//aTwsJCPp9/71Zy29bBGFMt+Hr5r7/uqnP1IgaTyuZA++CDunfvrp/n+wZf6Q4c/O2PC6eUSmW3rr0iZ0UxmUyFQhHSp/20qXNGj5pIbLP0u/nl5fxdOw6kpb+e/820Fd+t3Re9Iycny8HeccyYyWVlpef/iBcKKwICghZGLbe0tEIIXb5y/uzZkxmZ6SYmpu2COsyZvZB4Pv7U0T9vXg0PGxMdvbO0rKRZM5+FUctdXFxx/zMYMGml8vU9hvhFxwHtexW9q1QoFEwK89S2XFx5lErlwDZr/jwkQqj2mTVCiG1Kk4iVLTqaB4VY40inp3r06FFeXl7rSQcHh0uXLmFKVJthV7o3aaksNnvGtHlp6a/jTx21trYdP25q/W8Ri8Vbt62bP28Jk8XasXPjhl9+aNXKf8V3a98XFW7avGbn7s3fLf0RIfTy5TMXF9eQkP48XtnpM8dFYtHPP20l9vDq1fOTJw8tWLBcoVBs3vzTz+tX7t55UCcfl4REAsXhn7J7jmnk38POUJb1EfLlmc+El2IL+k9qhDuLvujcufOFCxcolH8nKqdQKKGhoVhD/T+GXemcnBpv2bSXRqP17h2ak5N56/a1j1Y6hNDMGfPbtw9GCI0IH7t+w+pvvl7q5ubRErVOTk5KenSf2Cbqm2XV3zY6nX74SIxUKmWxWMQzP63ZYm1tgxAaNixi1+4t5YJyC3O9XtZXPykV6gOrs8Z/b2Dz1nEtGa06W6U+4l+KKeg/GYodQghFRET89ddfRUVF1c80adIkIiICa6j/xzD+in4Il8OtvsnO1dWjuPh9Q97FYlYVLAaDiRBiMJnEl3Z29uXlVdMwyOXy4yd+nzItYuDgbhcvnVWpVHz+vyNa2WwT4oGDQyOEUGlJsUY/lrG4d66kx2hDrRQ+7SxNuPTMF/i7ifWBr69vQEBA9UKDarU6JCTExsYGd65/GXalq4lGoykUdVxCbrjq7j+1Wr3su/lHjsb06zto/bodIb36I4RU6jqmm2fQGQghpUr5Jcc1WlkvRBY2TNwpPh/ThFaYRbbFgD7buHHj7OzsiMeNGjXSt9UvyVPpqtW8WPB5UlKeJD959PW8JWHDRzf3benuZmCnVwZBIVdzrRhmVga8aLp1I5ZEDH/kqvj4+Pj5+RGP9a1BR85KR6PRzMzMS0qrzijVanVR0afdclwu4COEvJr51PxSpYIlhDSJQkHvs3Gu4/PlVEokLodK96/JkydbW1s3atRo3LhxuLPUZtg9Eh/SLqjDtasX2wQEWVvZnIw7nJOT1ex/Zashmvu2YjKZ+/bvCA0dmpGRdvRYLEIoMyPd2QnmmwXkUZIvLcmXigVKsUBJoaBKDbRPrbr4zjYxMXmSIEeoQRfN62FqRler1KbmNI453aEp28Lmi5r/5Kx0syMXSKXSdetXcjjcQQPDJFKJQFB7sE897Ozsl3/3085dm1atXtSiud/mTXtjD+w5feZ4cHA3baYGQBfe50hSH1dk/COiMalMEwaNSacxaDQGTaXSwJWEFn7dEEIVYg3kFEkoSplcmSNXK6UVZ0uZbKpna07zr8wtbD8nJ6W6u6SmRwllMglq3Q3GRpKBUqE++nNG5EYP3EH+H6VCvXdJxrgV+pXqk+SkirKeCUKnGkz3cXmp/O6ZErEI0dksrq0p09SQLpJKKmSiUrGYJ3ZyZwUPtmGZfNrMxuRs0wEAanlwsezlQ4Gdh7W9Fwd3ls/BNmOyzZg2rpa8XEHsyqyOA239On/CIFaodACQ39nd+YjB9ujYBHcQDbBqbG7V2Px1SklxnrRnhH0D30XCvlcAQE0nt+TSuWaWzqS6jcfOw7ZCRL9xvKgB2yKodACQ3KG1ORx7S66tPs4v8oUsnSzKK+jn9+Y3ZGOodACQ1qXYQktnC461Ce4g2mLd2EKBmA8uln50S6h0AJDTP3f5UgXDzF4fV3XQIGsXq4J3yqyP3YAMlQ4AcrpzuoRk1+Y+hGNrfuvUR5p1UOkAIKH750saeVl9+T3gBoHFYbDNWC8f1nd3AFQ6YEiEQuGbtNQv3MmkKSN++FHvltDWIJlMlZMmtXG1xB2kDkmPzy1c8ZVAUKLZ3dq4Wb18VMcc0dWg0gFDMnV6xOXL53Cn0HdZz0VqtXH9ajNYdFG5oijng3NGGNc/BzB0MpkMdwQDkJ4iMrUm4bCS+nFsOW+ffbBfQjP3SFxOOGVlqV/TUZEbi8UM8O+IO4WuRYwewOOVnT0Xd/ZcnIOD4/GjFxBCpaUlu/dsSXp0X6FQtGrpP3PGfHf3qvkEX756vmfv1tevX7LZJh07dJk16xtzM/Na+5RIJFu3rUtMvIMQ8vMLmBO50NHRYO5j/RBBmcLBRyu3fMlkksvXd//9T4JcLrWzbdoteIx/qxCE0J3EY0+fXe/ScdTl67srKkqcnXzCBy+1t6taSSov//XZS5vf5b00N7O1s3HRRjCEENfWtCiX96FXNVPppNJKX19vjewKNISJKQt3BAxWrdywaPEc/9Ztw8PGEHPiSySSqIUzBYLy6dPmsVnsYycORi2ceej3M2Zcs6ysjAULZ7q6eiz6dmU5nxd7YE9RUeGmjbtr7fPosdiEhAuTJs60sbFNuHrBxMTgh55VCpXlxTLH5prvi1CpVDFHFvB4BT26TOByrd9mJB8+uVwqq/yq7SCEUE7u89v3j4QPXqZUKuLP/3z89A/zZsQghN4XZ+2OmcUxtewfEkmj0q/ditZ4MAKDTc96W/mhVzVT6Xr17M/hkHzYjl5RqYzxJM7HuzmdTrexsW3Vyp945tr1Szk5WZs27m4TEIQQatUqYPTYQadPH58wftrhI9FUKnXD+h1mXDOEkJmZ+dp136ekPGnduk3NfRYU5puYmIweNZFOp4f2H4Lpk2mSuELBYH/aPB8N9Ozlzcysp8sWnLUwt0MItfHrI5WJ7z04QVQ6hNCkMRvNzWwQQsHtR/xx5VeRuJxjanExYTuFQp07I5rLsUIIUajU039s0EY8Gp2qViO5VMWoa5E5zVQ6Lgfmd9IpGtWAl1/QoJSUZC6HS5Q5hJCjYyMXF9fXb14ihJ6mJAcEBBFlDiEUFNQBIfT6zctala5Xz343blxZvGTu7MgF1ae9Bk1coWSwtTJzx6vX95UqxdrNQ6ufUamUJux/mzgsZlWL2MqyEUJIIChm0Fmv0x92CBpOlDmEEI2qxVlFWKY0UYXCklXHbwfMZQIMmFAktLC0qvmMubkFsVSbSCS0tPj3JTMzc4RQyX9WcfuqXcef1/66Z+/WKdMiQvsPmf/1EjqdBL8UdUw6+eUqhKXmZrYzJ+2s+SS1rspFpzGIOiioKFEqFdZWOrr0qVZ9cBkZEnxTgXGpOXesna39y5fPar5aVlbqYO+IELK1ta850TSPV4YQ4v6viVfTV+06BgW2P3X62K7dWxwcGo0bO0XLn0C7TM1oColWVrcwNTEXinhWlo0YjIZeJiaackLhBzsKNEtaqeSY1X3mDqNMgCExYZuUlv476LRFC7+KCsGrV8+JL9++TcvLe0dcxWvRwu9pSrJEUjXA6s6dGwgh4iUmg1lRISCeJ4atUKnU8LAxtrZ2aV88LBk7U3O6TDuVztMjSKVSJj46Vf2MVPbBHgACm82xtWmS8uKGQiHXRqSalHIVlUahM+uuadCmA4akVauAG39eOXrsgJmZeYvmfr169jtyNHbVD4vHjZ1KpVIPHdpvaWk1eFA4Qmjs6Ml//pmweOncgQOGFxUVHvz9twD/QP/WbRFCnp7ely6f27lr8/Rpc0+fOX4/8XZIr/6lpcUlJcXe3s1xf8QvZcKhmdsylAolja7hfom2rfslPT57IWE7j1/g3Mg7vzDt2ctbi+adYDLZ9byrd/epR+NXbv9tars2AyhU6t0HJzSbqpqsUu7k8cGuc6h0wJDMmD6vrKzk0OH9lhZWkZFR7u6ev6zfuWv35t17tqhUKr9WAbMjF1hZWSOEGjd22bBux2/7t2/4ZbWJiWlIr/4zZ8wnLuJMnTK7okJw5cr5CeOnOzk1lstku/ds4XC4w4ZFjByhd8v3fQZre4agSGzlVMep+peg0xnTJmy7dHXn3/9cffDXGTsbl47thtFoH6khbVr3raysuHX/yIWr2x3s3Js2aVlckq3ZYISKErGr5wd76mDFHPKDFXO0RG9XzHn7j/BhgsC5pQPuIDqV+VfewKkOtk51X0OENh0AZOPWwjQpgV/PBmq1esXaXnW+xDW1FIrreG8Lny6jhq/UXEa0c/+Mgvfp/33e0tyBL6hjrVgLc/tv5x770N5klQoLG/qHyhxUOgBIiEqjerYyzU4vs/Oo+7SMQqFERR6q8yWFQk6n17E6IpOp4btHxo5Yo1TW0U3xoQBUan2XHYvflgX1rO9sHSodACTUrq918qK31k0tafS6+yKtrZx0Hur/IW600IhKgVStkHu1qa/SwSgTAMip23C7ivz6JqckDVFxRfdw2/q3gUoHADn5fmXONVfxcitwB9Gu92mlbs1Zzp4fmaUKKh0ApNVrlL20Qsgv+MhqMoar6C3PwlLdtsfHZ1eGSgcAmUVENabIK8sLSNiyK83mObtS+45v0GAaqHSa8frNqx69gho+I27q65czZo4dMKjrl6+KAED9Bs9wZNGlvHc6uvlUB9QqdWFqUaPGlE4DGjrmF0+l+yZqxvadG+vZoLS0ZPn3C96/L9RhKPTs2dPVPyz5vPdmZb5t5OjEZDZoMiWJRPL9yoW9Q0LjTya4u5FhpiCg5/qOd3D3oafezOLlCnBn+VKl2fyXN7ICu5t1HPAJ85zjGWUSFNTBwaG+keVP/v4rNfWFg4NjA3eoVCppNFr9z3xUwtULn/qWahmZ6Y0bN3Ta6OTkpMpK8ZAhIxp4uM/4LADU0rqLpW8787tnSgpeFNLYTK4tx9TCkGauFpVVCkvEIp7YJ9Bs+MxPbh9gqHRjxw3Jy89du2YLQij2wJ6CwnwalXb33p90OmPO7IW9eva9fuPK+g2rKBRKv9Dg/v2HzJ29ECGUkHDhRNyh3NwcG2vb6dPnde8W8vDhvR/WLI0YOeHqtYstW7ZesmjV7j1bX795aW/vmJycNHXKbBaL/cvGHy7+cYdKpRKrEIQNHx02fPSUaRH+/oHPnz3NeZfl4eH17YIVTZu6bdn688VLZ5lMZr/Q4CWLV3ft0vOTPlRmZrpMLpswKaysrKRL557z5i5isVh1xj57Li46eqdSpZw0ZcSUyZFdu/TMzHy7a/fm5y9STE05gweFjx83FSFU67P06zvo5ctn+6N3vnz1jMViDwgdOm3qHK19iwA5MdnUnqPsBaXy18kVaU9LC0UqpimdzqRRGTQ6m6FWamVWu89GpVLlEplSrlQrVeXFlTZOLG9/ru9XNiyTz/mrj6HSrft527gJw9zcPInzuEePEr9dsGLO7IWbNq85cjSmV8++vXr2PXP2ROfg7hEjxxNvORl3+ODvvy1ZvLpNQLtz5+N++21b924hGZnpEomkkaPT4d/PVFZWIoSyst5mZWXMiVy4ZNEquVx++Ei0m5snUeaEQuH794UeHl7EdIyCcv6aHzfL5LIffliyfccvG3/ZNWvmNxcvnd26ZZ+vT4vP+FAZmeleXr7fL/85L+/dd8u/cXBoNH7c1DpjDxkc/uivRDtb+2/mL0UI5eXnfj1/6vjx0378YdOr1OcLFs7yb93Wzy+g1md5/jwlauHMsWOmrFy5Pic7c978qVDpwOcxt2EE9bYO6m0tLJeX5MnEAqVIoFCplLJK/ap0Jhw1otI45iyOBd2xqSOT/UWX2jBUuqzsDA6HQ6zAlJuX06f3gE6duiKE3N2bZedkIoQUCkV6+uvpU+cS21cIK2IP7Bk3dmrn4O5CofDt2zeubh5EcenUsWtISH+EELHQSUZm+rgxUzw9vRBCLBYrIzPdw70ZsZPMzHSEkLubp0QiEQjKx42damdnjxDq2bNvXPwRhNDr1y+pVKqnh9d/A587H3/w999qPnM6/mrNL8sF5aWlJePGTLG2trG2tunWLST5SdLQoSPrjI0QyshIC2zbnngcE7Ordeu2YcNHI4QC/APt7R3eZqT5+QXU+iy7924NCAgaP26qQqFIff3C7D9rXAHwqbgWDK5FHfddkRKGSpeRke7q+r/f+bdpXYJ7EI9z83JcmrgihNLSXysUCi8vX+L51NQXEokk/tTRY8cOyBXyDu07L/52JdGC69/v3yVOKoQVJSXFAf9bUgAhlJmRHjSiA/H4bUaanZ29hYXlq9QXTCbT2bkJ8bxAUG5hYYkQepX63NPTm8Go4xs/eFDY4EFh9XyizIx0KpXq9r++BbVarVQqPxSbaF26/a/qPforccrk2dVvLC/nW1lZ1/osMpns5ctnlpZWoQO7KBSKZs18Nqzf8Vn/9vpEjRq51Tevmf6j0ihcS7if0jBgqXRpRIejSCQqfF/g9r9lSt6mv+ncuQdC6NWr502aNK21Ht2JYxcrJZVcDpc4G1UoFDk5WTU7LjMz0ul0uotL1RKTlZWVBYX5bv8rqc9fpBCnrpmZ6a5N3YkL/CqV6sHDu+2/CiYO6tXMp87AH23TvX37pmlTNzabTRSyxAd3Bg4YXmfs6tYlEUylUonFYhubqhtZkh4lKpXKAP/AWp+FsGL5Wq9mviwWq85ybHBoDIqQpxCUysxtDHX1n5I8CZsD47QMA4bvU0ZmOtH8ychIo1Kprk3dicqVlZ1BVK7ych6fz8svyMvLz0UIeXp4MZnMI0dj1CpVVlZGbt47hFBe3ju5XF7dMkIIZWa9dXFxrV7uRCaXIYRKy0oQQteuX7516xpxJpuRkU6j0/l83rt32T+vXykSCUeMGIcQ4vHL8vNzS0tLiouLagUePCjsdPzVmv/V2uDlq2cyqfT9+8Ls7Mzl30dxuWbhYWPqjE18fAsLS0tLK+Kaq4d7s5s3r0okkqysjB07N44ZPdnCwrLWZ2Eymc08vePij4hEQh6vrNbKCYbLraUpv9iAl3OUVSodDbxZajx0XemkUmle3juiohEjM4gxaDk5WQqFgmjfdesawmazJ0wcvn//DoSQlZX1ksWrr12/HD6y3+ofl8hlMuK9Nja2xIknITMzvboFhxCyMLcYMjj8l40/jB03JCMjjU6nu7s3IzaTy2TjJw6fNXu8Qi7/dct+C3MLhNCggWEvXv4zZtzgu3f//KRPpFKpXrz8p1ev/jNmjZ07b7Kjo9OvW/ZxOJw6YxP1vWbOb7/9vqAgb8iwnsu/XzB0yMgJ46f997MghBYvWlVezp8wafjsuROJPwAkEDzE7tbJQoVchTvI50i5XapWqZr6cHAHAQ1idHMODwvrvWTx6nZBHXAFmDp9VFBghxnT5+nsiPo55zBBJlH9tiyjR4SjlQOLa2kYZ+WlBZLMfyqoNNR1uMbmHQLappnrdJOmjKj1jEqlolKo6D9LL+7/7RjGQbB8Po/HKyP6PbDYtuMXgaB86JCRuALoGyabOmez572zJX9dKbGwZxZlS3An+ggTLo3BorboYNaq08fvKgf6QzOVLjb6pEb2o20ZmeksFqvht15onI9X88kTZ3G53AZsa0SCh9gGD7GVVar0a0BXXZgsKgU6IQyQcfWRtwkIunLpPsYAvXuHYjy6nmOaQAkB2gI/WwAA8oNKBwAgP6h0AADyg0oHACA/qHQAAPKDSgcAID+odAAA8oNKBwAgP6h0AADyg0oHACA/qHQAAPKDSgcAID+odAAA8qt7LhMmm6L679xywDBRKMjRFSYBB0at7jadmRWjOLtS52GAVpQWSBUyg5zBHABNqbvS2TdhUaBJRxblJbKmLWC5A2DUPtimc/Zk3zlVqPM8QMP4xdK/b5R+1YeES4IA0HB1r5hDePGgPO2psHVXGysHJo0OfRcGpqJMXpoveXCheMoaNxoNmujAqNVX6RBCmS9ET2/zCzMlNDr8qhgSexe2oFTm6c/tOMAWdxYA8PtIpasmrYRL2oaEQkFMNjTDAajS0EoHAACGC/7sAwDIDyodAID8oNIBAMgPKh0AgPyg0gEAyA8qHQCA/P4PlORXxA5z/Y4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "  display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1_am72or2IP",
        "outputId": "a587fbc4-992a-4ced-fef1-3c46520b0e2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "I need some expert guidence for building this ai agent, could you request assistant for me?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  RequestAssistance (dce12075-5d10-4ebb-8973-0d1cfd900fb5)\n",
            " Call ID: dce12075-5d10-4ebb-8973-0d1cfd900fb5\n",
            "  Args:\n",
            "    request: I need some expert guidence for building this ai agent.\n"
          ]
        }
      ],
      "source": [
        "user_input = \"I need some expert guidence for building this ai agent, could you request assistant for me?\"\n",
        "config = {\"configurable\": {\"thread_id\": \"71\"}}\n",
        "\n",
        "events = graph.stream(\n",
        "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
        ")\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "      event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jTOJ-yOtN-W",
        "outputId": "067451cb-1448-4a60-f625-bd98a65a0208"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('human',)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "snapshot = graph.get_state(config)\n",
        "snapshot.next"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "oiEOwDGXtnxk"
      },
      "outputs": [],
      "source": [
        "ai_message = snapshot.values[\"messages\"][-1]\n",
        "human_response = (\n",
        "    \"We, the experts are here to help! We'd recommend you check out LangGraph to build your agent.\"\n",
        "    \" It's much more reliable and extensible than simple autonomous agents.\"\n",
        ")\n",
        "\n",
        "if ai_message.tool_calls:\n",
        "    tool_message = create_response(human_response, ai_message)\n",
        "else:\n",
        "    # Handle the case where tool_calls is empty\n",
        "    print(\"No tool calls found\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cmowf4cnDxcr"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4rO3ozn1PoG",
        "outputId": "c774cf3c-9a18-4fcf-8777-827a6537abd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\n",
            "We, the experts are here to help! We'd recommend you check out LangGraph to build your agent. It's much more reliable and extensible than simple autonomous agents.\n"
          ]
        }
      ],
      "source": [
        "tool_message.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMzcxSNZy5-z",
        "outputId": "168bed51-a608-4073-a5a3-81d2f12d92c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'configurable': {'thread_id': '71',\n",
              "  'checkpoint_ns': '',\n",
              "  'checkpoint_id': '1efe1436-be3d-6833-8002-2868f853980d'}}"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "graph.update_state(config, {\"messages\": [tool_message]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhw5cQJi1hka",
        "outputId": "60912185-e999-4f42-b409-0d7b31c6cb14"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='I need some expert guidence for building this ai agent, could you request assistant for me?', additional_kwargs={}, response_metadata={}, id='9cc156e5-5354-4993-acc0-4e58c7cd072b'),\n",
              " AIMessage(content='', additional_kwargs={'function_call': {'name': 'RequestAssistance', 'arguments': '{\"request\": \"I need some expert guidence for building this ai agent.\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-39193bad-b5a3-4e21-9f46-0a3f5715ccf7-0', tool_calls=[{'name': 'RequestAssistance', 'args': {'request': 'I need some expert guidence for building this ai agent.'}, 'id': 'dce12075-5d10-4ebb-8973-0d1cfd900fb5', 'type': 'tool_call'}], usage_metadata={'input_tokens': 133, 'output_tokens': 15, 'total_tokens': 148, 'input_token_details': {'cache_read': 0}}),\n",
              " ToolMessage(content=\"We, the experts are here to help! We'd recommend you check out LangGraph to build your agent. It's much more reliable and extensible than simple autonomous agents.\", id='50ef7ef6-0279-422e-8e93-75cfd02e67fb', tool_call_id='dce12075-5d10-4ebb-8973-0d1cfd900fb5')]"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "graph.get_state(config).values[\"messages\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "SF6ydvPf2IOk",
        "outputId": "6de53372-e627-4949-b956-6bc7b4d88287"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\n",
            "We, the experts are here to help! We'd recommend you check out LangGraph to build your agent. It's much more reliable and extensible than simple autonomous agents.\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\n",
            "We, the experts are here to help! We'd recommend you check out LangGraph to build your agent. It's much more reliable and extensible than simple autonomous agents.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ChatGoogleGenerativeAIError",
          "evalue": "Invalid argument provided to Gemini: 400 * GenerateContentRequest.contents[2].parts[0].function_response.name: Name cannot be empty.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;31m# Do not retry for these errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    836\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m             )\n\u001b[0;32m--> 293\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             _retry_error_helper(\n\u001b[0m\u001b[1;32m    154\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    211\u001b[0m         )\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgument\u001b[0m: 400 * GenerateContentRequest.contents[2].parts[0].function_response.name: Name cannot be empty.\n",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mChatGoogleGenerativeAIError\u001b[0m               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-2fdd3da406c1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"values\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"messages\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mevent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1722\u001b[0m                 \u001b[0;31m# with channel updates applied only at the transition between steps.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1724\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   1725\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    231\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m                 )\n\u001b[1;32m    494\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_set_config_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-92-f7bf4e97285a>\u001b[0m in \u001b[0;36mchatbot\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mchatbot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm_with_tools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mask_human\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     if (\n\u001b[1;32m      5\u001b[0m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_calls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5350\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5351\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5352\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   5353\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5354\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m         return cast(\n\u001b[1;32m    283\u001b[0m             \u001b[0mChatGeneration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    285\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    858\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    859\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m                 results.append(\n\u001b[0;32m--> 690\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    691\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m                 result = self._generate(\n\u001b[0m\u001b[1;32m    926\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0mtool_choice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtool_choice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m         )\n\u001b[0;32m--> 951\u001b[0;31m         response: GenerateContentResponse = _chat_with_retry(\n\u001b[0m\u001b[1;32m    952\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mwrapped_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_post_retry_check_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_state\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"RetryCallState\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_explicit_retry\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_run_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m                     \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgument\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             raise ChatGoogleGenerativeAIError(\n\u001b[0m\u001b[1;32m    191\u001b[0m                 \u001b[0;34mf\"Invalid argument provided to Gemini: {e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             ) from e\n",
            "\u001b[0;31mChatGoogleGenerativeAIError\u001b[0m: Invalid argument provided to Gemini: 400 * GenerateContentRequest.contents[2].parts[0].function_response.name: Name cannot be empty.\n"
          ]
        }
      ],
      "source": [
        "events = graph.stream(None, config, stream_mode=\"values\")\n",
        "\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "      event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANJ5j_LwCpSa",
        "outputId": "8f03b7c0-5dd4-449a-8ba5-556df4afc7a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "I need some expert guidence for building this ai agent, could you request assistant for me?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  RequestAssistance (dce12075-5d10-4ebb-8973-0d1cfd900fb5)\n",
            " Call ID: dce12075-5d10-4ebb-8973-0d1cfd900fb5\n",
            "  Args:\n",
            "    request: I need some expert guidence for building this ai agent.\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\n",
            "We, the experts are here to help! We'd recommend you check out LangGraph to build your agent. It's much more reliable and extensible than simple autonomous agents.\n"
          ]
        }
      ],
      "source": [
        "for m in graph.get_state(config).values[\"messages\"]:\n",
        "  m.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6DsPhABp6rR",
        "outputId": "551fc587-de90-4ffd-fbed-7ef321b853ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "hello!, I'm learning ai agents. \n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello!  I can help you learn about AI agents. What specifically about AI agents are you interested in learning?  For example, are you interested in a particular type of AI agent, a specific application, or the underlying concepts?  The more detail you provide, the better I can assist you.\n"
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"101\"}}\n",
        "events = graph.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": (\n",
        "                    \"hello!, I'm learning ai agents. \"\n",
        "\n",
        "                ),\n",
        "            },\n",
        "        ],\n",
        "    },\n",
        "    config,\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5geQLNNqR7N",
        "outputId": "f3dc9a03-581a-4fae-e341-92d32f8c1464"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Ya that's helpful. Maybe I'll build an autonomous agent with it!\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "That's a great goal! Building an autonomous agent is a challenging but rewarding project. To help you get started, let's break down the process.  We need to consider several key aspects:\n",
            "\n",
            "1. **Define the Environment:** What kind of environment will your agent operate in?  Will it be a simulated environment (like a game) or a real-world environment?  The environment dictates the types of sensors and actions your agent will need.\n",
            "\n",
            "2. **Define the Agent's Goals:** What is the agent supposed to achieve?  This is crucial for designing the reward function and the overall agent architecture.  A clear objective helps guide the development process.\n",
            "\n",
            "3. **Choose an Agent Architecture:**  There are several options, each with its strengths and weaknesses:\n",
            "    * **Rule-based agents:**  These agents follow a set of pre-defined rules.  Simple to implement but not very adaptable.\n",
            "    * **Reactive agents:** These agents react directly to their current sensory input.  More adaptable than rule-based agents but still limited in their planning capabilities.\n",
            "    * **Model-based agents:** These agents build an internal model of the environment and use it to plan their actions. More complex but capable of more sophisticated behavior.\n",
            "    * **Reinforcement learning agents:** These agents learn through trial and error, interacting with the environment and receiving rewards or penalties based on their actions.  Very powerful but require significant computational resources and careful design.\n",
            "\n",
            "\n",
            "4. **Select Appropriate Algorithms and Technologies:**  The choice of algorithms and technologies will depend on the agent architecture and environment.  For example, reinforcement learning agents often use algorithms like Q-learning or Deep Q-Networks (DQN).\n",
            "\n",
            "5. **Implementation and Testing:**  This involves writing the code, training the agent (if necessary), and thoroughly testing its performance.\n",
            "\n",
            "To proceed, tell me more about the kind of autonomous agent you envision.  What environment will it operate in? What are its goals?  What level of complexity are you aiming for?  The more detail you provide, the better I can assist you in planning and building your agent.\n"
          ]
        }
      ],
      "source": [
        "events = graph.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": (\n",
        "                    \"Ya that's helpful. Maybe I'll \"\n",
        "                    \"build an autonomous agent with it!\"\n",
        "                ),\n",
        "            },\n",
        "        ],\n",
        "    },\n",
        "    config,\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bkgLdy3qaLy",
        "outputId": "8768d187-f6e1-4509-ee01-ac98bb7bddf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StateSnapshot(values={'messages': [HumanMessage(content=\"hello!, I'm learning ai agents. \", additional_kwargs={}, response_metadata={}, id='fd290614-0b55-473a-8051-e6df92c766bf'), AIMessage(content='Hello!  I can help you learn about AI agents. What specifically about AI agents are you interested in learning?  For example, are you interested in a particular type of AI agent, a specific application, or the underlying concepts?  The more detail you provide, the better I can assist you.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-8f2d08b3-e9ea-4b52-a735-6b908b1945a1-0', usage_metadata={'input_tokens': 124, 'output_tokens': 62, 'total_tokens': 186, 'input_token_details': {'cache_read': 0}}), HumanMessage(content=\"Ya that's helpful. Maybe I'll build an autonomous agent with it!\", additional_kwargs={}, response_metadata={}, id='717ae4d1-1350-455d-adac-f573e4c846bb'), AIMessage(content=\"That's a great goal! Building an autonomous agent is a challenging but rewarding project. To help you get started, let's break down the process.  We need to consider several key aspects:\\n\\n1. **Define the Environment:** What kind of environment will your agent operate in?  Will it be a simulated environment (like a game) or a real-world environment?  The environment dictates the types of sensors and actions your agent will need.\\n\\n2. **Define the Agent's Goals:** What is the agent supposed to achieve?  This is crucial for designing the reward function and the overall agent architecture.  A clear objective helps guide the development process.\\n\\n3. **Choose an Agent Architecture:**  There are several options, each with its strengths and weaknesses:\\n    * **Rule-based agents:**  These agents follow a set of pre-defined rules.  Simple to implement but not very adaptable.\\n    * **Reactive agents:** These agents react directly to their current sensory input.  More adaptable than rule-based agents but still limited in their planning capabilities.\\n    * **Model-based agents:** These agents build an internal model of the environment and use it to plan their actions. More complex but capable of more sophisticated behavior.\\n    * **Reinforcement learning agents:** These agents learn through trial and error, interacting with the environment and receiving rewards or penalties based on their actions.  Very powerful but require significant computational resources and careful design.\\n\\n\\n4. **Select Appropriate Algorithms and Technologies:**  The choice of algorithms and technologies will depend on the agent architecture and environment.  For example, reinforcement learning agents often use algorithms like Q-learning or Deep Q-Networks (DQN).\\n\\n5. **Implementation and Testing:**  This involves writing the code, training the agent (if necessary), and thoroughly testing its performance.\\n\\nTo proceed, tell me more about the kind of autonomous agent you envision.  What environment will it operate in? What are its goals?  What level of complexity are you aiming for?  The more detail you provide, the better I can assist you in planning and building your agent.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-bba4de55-5c77-4213-ba0b-b3765a959f1c-0', usage_metadata={'input_tokens': 204, 'output_tokens': 437, 'total_tokens': 641, 'input_token_details': {'cache_read': 0}})], 'ask_human': True}, next=('human',), config={'configurable': {'thread_id': '101', 'checkpoint_ns': '', 'checkpoint_id': '1efe1437-469f-6dac-8004-e935a7696b78'}}, metadata={'source': 'loop', 'writes': {'chatbot': {'messages': [AIMessage(content=\"That's a great goal! Building an autonomous agent is a challenging but rewarding project. To help you get started, let's break down the process.  We need to consider several key aspects:\\n\\n1. **Define the Environment:** What kind of environment will your agent operate in?  Will it be a simulated environment (like a game) or a real-world environment?  The environment dictates the types of sensors and actions your agent will need.\\n\\n2. **Define the Agent's Goals:** What is the agent supposed to achieve?  This is crucial for designing the reward function and the overall agent architecture.  A clear objective helps guide the development process.\\n\\n3. **Choose an Agent Architecture:**  There are several options, each with its strengths and weaknesses:\\n    * **Rule-based agents:**  These agents follow a set of pre-defined rules.  Simple to implement but not very adaptable.\\n    * **Reactive agents:** These agents react directly to their current sensory input.  More adaptable than rule-based agents but still limited in their planning capabilities.\\n    * **Model-based agents:** These agents build an internal model of the environment and use it to plan their actions. More complex but capable of more sophisticated behavior.\\n    * **Reinforcement learning agents:** These agents learn through trial and error, interacting with the environment and receiving rewards or penalties based on their actions.  Very powerful but require significant computational resources and careful design.\\n\\n\\n4. **Select Appropriate Algorithms and Technologies:**  The choice of algorithms and technologies will depend on the agent architecture and environment.  For example, reinforcement learning agents often use algorithms like Q-learning or Deep Q-Networks (DQN).\\n\\n5. **Implementation and Testing:**  This involves writing the code, training the agent (if necessary), and thoroughly testing its performance.\\n\\nTo proceed, tell me more about the kind of autonomous agent you envision.  What environment will it operate in? What are its goals?  What level of complexity are you aiming for?  The more detail you provide, the better I can assist you in planning and building your agent.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-bba4de55-5c77-4213-ba0b-b3765a959f1c-0', usage_metadata={'input_tokens': 204, 'output_tokens': 437, 'total_tokens': 641, 'input_token_details': {'cache_read': 0}})], 'ask_human': True}}, 'thread_id': '101', 'step': 4, 'parents': {}}, created_at='2025-02-02T08:55:30.393612+00:00', parent_config={'configurable': {'thread_id': '101', 'checkpoint_ns': '', 'checkpoint_id': '1efe1437-26b4-6bb0-8003-4b4ef4a1bfc9'}}, tasks=(PregelTask(id='cc8b003d-f1b5-57e1-198d-0c8bef9cd91b', name='human', path=('__pregel_pull', 'human'), error=None, interrupts=(), state=None, result=None),))\n",
            "StateSnapshot(values={'messages': [HumanMessage(content=\"hello!, I'm learning ai agents. \", additional_kwargs={}, response_metadata={}, id='fd290614-0b55-473a-8051-e6df92c766bf'), AIMessage(content='Hello!  I can help you learn about AI agents. What specifically about AI agents are you interested in learning?  For example, are you interested in a particular type of AI agent, a specific application, or the underlying concepts?  The more detail you provide, the better I can assist you.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-8f2d08b3-e9ea-4b52-a735-6b908b1945a1-0', usage_metadata={'input_tokens': 124, 'output_tokens': 62, 'total_tokens': 186, 'input_token_details': {'cache_read': 0}}), HumanMessage(content=\"Ya that's helpful. Maybe I'll build an autonomous agent with it!\", additional_kwargs={}, response_metadata={}, id='717ae4d1-1350-455d-adac-f573e4c846bb')], 'ask_human': True}, next=('chatbot',), config={'configurable': {'thread_id': '101', 'checkpoint_ns': '', 'checkpoint_id': '1efe1437-26b4-6bb0-8003-4b4ef4a1bfc9'}}, metadata={'source': 'loop', 'writes': None, 'thread_id': '101', 'step': 3, 'parents': {}}, created_at='2025-02-02T08:55:27.046713+00:00', parent_config={'configurable': {'thread_id': '101', 'checkpoint_ns': '', 'checkpoint_id': '1efe1437-266c-6e4c-8002-bec6ae7f978f'}}, tasks=(PregelTask(id='317b20d5-ae37-bc82-525d-c31efa299dc4', name='chatbot', path=('__pregel_pull', 'chatbot'), error=None, interrupts=(), state=None, result={'messages': [AIMessage(content=\"That's a great goal! Building an autonomous agent is a challenging but rewarding project. To help you get started, let's break down the process.  We need to consider several key aspects:\\n\\n1. **Define the Environment:** What kind of environment will your agent operate in?  Will it be a simulated environment (like a game) or a real-world environment?  The environment dictates the types of sensors and actions your agent will need.\\n\\n2. **Define the Agent's Goals:** What is the agent supposed to achieve?  This is crucial for designing the reward function and the overall agent architecture.  A clear objective helps guide the development process.\\n\\n3. **Choose an Agent Architecture:**  There are several options, each with its strengths and weaknesses:\\n    * **Rule-based agents:**  These agents follow a set of pre-defined rules.  Simple to implement but not very adaptable.\\n    * **Reactive agents:** These agents react directly to their current sensory input.  More adaptable than rule-based agents but still limited in their planning capabilities.\\n    * **Model-based agents:** These agents build an internal model of the environment and use it to plan their actions. More complex but capable of more sophisticated behavior.\\n    * **Reinforcement learning agents:** These agents learn through trial and error, interacting with the environment and receiving rewards or penalties based on their actions.  Very powerful but require significant computational resources and careful design.\\n\\n\\n4. **Select Appropriate Algorithms and Technologies:**  The choice of algorithms and technologies will depend on the agent architecture and environment.  For example, reinforcement learning agents often use algorithms like Q-learning or Deep Q-Networks (DQN).\\n\\n5. **Implementation and Testing:**  This involves writing the code, training the agent (if necessary), and thoroughly testing its performance.\\n\\nTo proceed, tell me more about the kind of autonomous agent you envision.  What environment will it operate in? What are its goals?  What level of complexity are you aiming for?  The more detail you provide, the better I can assist you in planning and building your agent.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-bba4de55-5c77-4213-ba0b-b3765a959f1c-0', usage_metadata={'input_tokens': 204, 'output_tokens': 437, 'total_tokens': 641, 'input_token_details': {'cache_read': 0}})], 'ask_human': True}),))\n",
            "StateSnapshot(values={'messages': [HumanMessage(content=\"hello!, I'm learning ai agents. \", additional_kwargs={}, response_metadata={}, id='fd290614-0b55-473a-8051-e6df92c766bf'), AIMessage(content='Hello!  I can help you learn about AI agents. What specifically about AI agents are you interested in learning?  For example, are you interested in a particular type of AI agent, a specific application, or the underlying concepts?  The more detail you provide, the better I can assist you.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-8f2d08b3-e9ea-4b52-a735-6b908b1945a1-0', usage_metadata={'input_tokens': 124, 'output_tokens': 62, 'total_tokens': 186, 'input_token_details': {'cache_read': 0}})], 'ask_human': True}, next=('__start__',), config={'configurable': {'thread_id': '101', 'checkpoint_ns': '', 'checkpoint_id': '1efe1437-266c-6e4c-8002-bec6ae7f978f'}}, metadata={'source': 'input', 'writes': {'__start__': {'messages': [{'role': 'user', 'content': \"Ya that's helpful. Maybe I'll build an autonomous agent with it!\"}]}}, 'thread_id': '101', 'step': 2, 'parents': {}}, created_at='2025-02-02T08:55:27.017277+00:00', parent_config={'configurable': {'thread_id': '101', 'checkpoint_ns': '', 'checkpoint_id': '1efe1437-15e7-6c3c-8001-cd7220b170ff'}}, tasks=(PregelTask(id='c86adf06-66b7-62ed-2319-ff95aff70346', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'messages': [{'role': 'user', 'content': \"Ya that's helpful. Maybe I'll build an autonomous agent with it!\"}]}),))\n",
            "StateSnapshot(values={'messages': [HumanMessage(content=\"hello!, I'm learning ai agents. \", additional_kwargs={}, response_metadata={}, id='fd290614-0b55-473a-8051-e6df92c766bf'), AIMessage(content='Hello!  I can help you learn about AI agents. What specifically about AI agents are you interested in learning?  For example, are you interested in a particular type of AI agent, a specific application, or the underlying concepts?  The more detail you provide, the better I can assist you.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-8f2d08b3-e9ea-4b52-a735-6b908b1945a1-0', usage_metadata={'input_tokens': 124, 'output_tokens': 62, 'total_tokens': 186, 'input_token_details': {'cache_read': 0}})], 'ask_human': True}, next=('human',), config={'configurable': {'thread_id': '101', 'checkpoint_ns': '', 'checkpoint_id': '1efe1437-15e7-6c3c-8001-cd7220b170ff'}}, metadata={'source': 'loop', 'writes': {'chatbot': {'messages': [AIMessage(content='Hello!  I can help you learn about AI agents. What specifically about AI agents are you interested in learning?  For example, are you interested in a particular type of AI agent, a specific application, or the underlying concepts?  The more detail you provide, the better I can assist you.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-8f2d08b3-e9ea-4b52-a735-6b908b1945a1-0', usage_metadata={'input_tokens': 124, 'output_tokens': 62, 'total_tokens': 186, 'input_token_details': {'cache_read': 0}})], 'ask_human': True}}, 'thread_id': '101', 'step': 1, 'parents': {}}, created_at='2025-02-02T08:55:25.285049+00:00', parent_config={'configurable': {'thread_id': '101', 'checkpoint_ns': '', 'checkpoint_id': '1efe1437-0e9f-6b44-8000-241d9a6c457c'}}, tasks=(PregelTask(id='92c719b3-4d6c-588c-46c1-deb83bdf1605', name='human', path=('__pregel_pull', 'human'), error=None, interrupts=(), state=None, result=None),))\n",
            "StateSnapshot(values={'messages': [HumanMessage(content=\"hello!, I'm learning ai agents. \", additional_kwargs={}, response_metadata={}, id='fd290614-0b55-473a-8051-e6df92c766bf')]}, next=('chatbot',), config={'configurable': {'thread_id': '101', 'checkpoint_ns': '', 'checkpoint_id': '1efe1437-0e9f-6b44-8000-241d9a6c457c'}}, metadata={'source': 'loop', 'writes': None, 'thread_id': '101', 'step': 0, 'parents': {}}, created_at='2025-02-02T08:55:24.521527+00:00', parent_config={'configurable': {'thread_id': '101', 'checkpoint_ns': '', 'checkpoint_id': '1efe1437-0e86-686c-bfff-4fceef0f5af1'}}, tasks=(PregelTask(id='b08d1bc7-078b-8f92-3e01-81f2e2fe7808', name='chatbot', path=('__pregel_pull', 'chatbot'), error=None, interrupts=(), state=None, result={'messages': [AIMessage(content='Hello!  I can help you learn about AI agents. What specifically about AI agents are you interested in learning?  For example, are you interested in a particular type of AI agent, a specific application, or the underlying concepts?  The more detail you provide, the better I can assist you.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-8f2d08b3-e9ea-4b52-a735-6b908b1945a1-0', usage_metadata={'input_tokens': 124, 'output_tokens': 62, 'total_tokens': 186, 'input_token_details': {'cache_read': 0}})], 'ask_human': True}),))\n",
            "StateSnapshot(values={'messages': []}, next=('__start__',), config={'configurable': {'thread_id': '101', 'checkpoint_ns': '', 'checkpoint_id': '1efe1437-0e86-686c-bfff-4fceef0f5af1'}}, metadata={'source': 'input', 'writes': {'__start__': {'messages': [{'role': 'user', 'content': \"hello!, I'm learning ai agents. \"}]}}, 'thread_id': '101', 'step': -1, 'parents': {}}, created_at='2025-02-02T08:55:24.511220+00:00', parent_config=None, tasks=(PregelTask(id='1fe66782-87d0-2718-f7c6-1b9dccee9bc5', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'messages': [{'role': 'user', 'content': \"hello!, I'm learning ai agents. \"}]}),))\n"
          ]
        }
      ],
      "source": [
        "to_replay = []\n",
        "for state in graph.get_state_history(config):\n",
        "  print(state)\n",
        "  to_replay.append(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5ub9hDZqpD7",
        "outputId": "95b7e2b7-7b20-42cd-c156-0c3249e2b055"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num Messages:  4 Next:  ('human',)\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages:  3 Next:  ('chatbot',)\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages:  2 Next:  ('__start__',)\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages:  2 Next:  ('human',)\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages:  1 Next:  ('chatbot',)\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages:  0 Next:  ('__start__',)\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "to_replay = None\n",
        "for state in graph.get_state_history(config):\n",
        "    print(\"Num Messages: \", len(state.values[\"messages\"]), \"Next: \", state.next)\n",
        "    print(\"-\" * 80)\n",
        "    if len(state.values[\"messages\"]) == 1:\n",
        "        # We are somewhat arbitrarily selecting a specific state based on the number of chat messages in the state.\n",
        "        to_replay = state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsk2_S5LwJJW",
        "outputId": "6a1e551c-d25d-4af1-aef0-76abb07dcfae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('chatbot',)\n",
            "{'configurable': {'thread_id': '101', 'checkpoint_ns': '', 'checkpoint_id': '1efe1437-0e9f-6b44-8000-241d9a6c457c'}}\n"
          ]
        }
      ],
      "source": [
        "print(to_replay.next)\n",
        "print(to_replay.config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXikTnF0xJm3",
        "outputId": "50fca0c1-21ad-42db-955b-288b7bad6c6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StateSnapshot(values={'messages': [HumanMessage(content=\"hello!, I'm learning ai agents. \", additional_kwargs={}, response_metadata={}, id='fd290614-0b55-473a-8051-e6df92c766bf')]}, next=('chatbot',), config={'configurable': {'thread_id': '101', 'checkpoint_ns': '', 'checkpoint_id': '1efe1437-0e9f-6b44-8000-241d9a6c457c'}}, metadata={'source': 'loop', 'writes': None, 'thread_id': '101', 'step': 0, 'parents': {}}, created_at='2025-02-02T08:55:24.521527+00:00', parent_config={'configurable': {'thread_id': '101', 'checkpoint_ns': '', 'checkpoint_id': '1efe1437-0e86-686c-bfff-4fceef0f5af1'}}, tasks=(PregelTask(id='b08d1bc7-078b-8f92-3e01-81f2e2fe7808', name='chatbot', path=('__pregel_pull', 'chatbot'), error=None, interrupts=(), state=None, result={'messages': [AIMessage(content='Hello!  I can help you learn about AI agents. What specifically about AI agents are you interested in learning?  For example, are you interested in a particular type of AI agent, a specific application, or the underlying concepts?  The more detail you provide, the better I can assist you.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-8f2d08b3-e9ea-4b52-a735-6b908b1945a1-0', usage_metadata={'input_tokens': 124, 'output_tokens': 62, 'total_tokens': 186, 'input_token_details': {'cache_read': 0}})], 'ask_human': True}),))\n"
          ]
        }
      ],
      "source": [
        "print(to_replay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "lC7WMjDARaO1"
      },
      "outputs": [],
      "source": [
        "config = {\"configurable\": {\"thread id\": 200}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-zSrBPs0FK0",
        "outputId": "5bbdc4e5-ae8e-4c5d-d4d5-f4d3197d08c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: hi\n",
            "Error: Checkpointer requires one or more of the following 'configurable' keys: ['thread_id', 'checkpoint_ns', 'checkpoint_id']\n",
            "User: q\n",
            "Goodbye!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        # Get user input\n",
        "        user_input = input(\"User: \")\n",
        "\n",
        "        # Check if the user wants to quit\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "\n",
        "        # Ensure that the configuration is correct for Checkpointer\n",
        "        # You might need to define a config dictionary with the required keys\n",
        "        config = {\n",
        "            'thread_id': config,  # Thread ID dynamically obtained\n",
        "            'checkpoint_ns': '',  # Define the checkpoint namespace\n",
        "            'checkpoint_id': '1efe0040-c516-61f4-8000-1c3d5770ed83'  # Use the generated checkpoint ID\n",
        "        }\n",
        "\n",
        "        # Assuming stream_graph_updates is part of LangGraph, pass the config to it\n",
        "        # Modify stream_graph_updates to accept the config if needed\n",
        "        stream_graph_updates(user_input)\n",
        "\n",
        "    except ValueError as e:\n",
        "        # Handle ValueError specifically, especially from LangGraph's Checkpointer\n",
        "        print(f\"Error: {e}\")\n",
        "        # You can decide if you want to continue or exit on error\n",
        "        continue\n",
        "\n",
        "    except Exception as e:\n",
        "        # Catch other exceptions and print the error\n",
        "        print(f\"Unexpected error: {e}\")\n",
        "        break  # Exit loop in case of unexpected error\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "bnFSTGhGZgGN",
        "outputId": "405dafa5-d27f-4e41-9222-f02977e03ecc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'thread_id'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-121-63e608abad02>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msnapshot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnapshot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mget_state\u001b[0;34m(self, config, subgraphs)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m         \u001b[0msaved\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpointer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m         return self._prepare_state_snapshot(\n\u001b[1;32m    717\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/checkpoint/memory/__init__.py\u001b[0m in \u001b[0;36mget_tuple\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCheckpointTuple\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mretrieved\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mno\u001b[0m \u001b[0mmatching\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0mwas\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \"\"\"\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mthread_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"configurable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"thread_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mcheckpoint_ns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"configurable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"checkpoint_ns\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheckpoint_id\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mget_checkpoint_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'thread_id'"
          ]
        }
      ],
      "source": [
        "snapshot = graph.get_state(config)\n",
        "print(snapshot)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    try:\n",
        "        # Get user input\n",
        "        user_input = input(\"User: \")\n",
        "\n",
        "        # Check if the user wants to quit\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # Ensure that the configuration is correct for Checkpointer\n",
        "        config = {\n",
        "            'thread_id': '71',  # Thread ID dynamically obtained\n",
        "            'checkpoint_ns': '',  # Define the checkpoint namespace if needed\n",
        "            'checkpoint_id': '1efe0040-c516-61f4-8000-1c3d5770ed83'  # Use the generated checkpoint ID\n",
        "        }\n",
        "\n",
        "        # Assuming stream_graph_updates is part of LangGraph, pass the config to it\n",
        "        # Modify stream_graph_updates to accept the config if needed\n",
        "        stream_graph_updates(user_input)\n",
        "\n",
        "        # If using the stream functionality as per the original code snippet\n",
        "        events = graph.stream(\n",
        "            {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
        "        )\n",
        "\n",
        "        # Process the event if \"messages\" is present\n",
        "        for event in events:\n",
        "            if \"messages\" in event:\n",
        "                # Assuming pretty_print method exists to display the message content\n",
        "                event[\"messages\"][-1].pretty_print()\n",
        "\n",
        "    except ValueError as e:\n",
        "        # Handle ValueError specifically, especially from LangGraph's Checkpointer\n",
        "        print(f\"Error: {e}\")\n",
        "        # You can decide if you want to continue or exit on error\n",
        "        continue\n",
        "\n",
        "    except Exception as e:\n",
        "        # Catch other exceptions and print the error\n",
        "        print(f\"Unexpected error: {e}\")\n",
        "        break  # Exit loop in case of unexpected error\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6ZLFoDfb7ql",
        "outputId": "549b5394-9781-48db-d672-2b7c310f117d"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: hi\n",
            "Error: Checkpointer requires one or more of the following 'configurable' keys: ['thread_id', 'checkpoint_ns', 'checkpoint_id']\n",
            "User: q\n",
            "Goodbye!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2PXOrM0qfJ6D2dcQs81LX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}